Loading rhel8/default-amp
  Loading requirement: dot rhel8/slurm singularity/current rhel8/global
    cuda/11.4 libpciaccess/0.16/gcc-9.4.0-6fonbj6
    libiconv/1.16/gcc-9.4.0-ahebbov libxml2/2.9.12/gcc-9.4.0-gnknt5e
    ncurses/6.2/gcc-9.4.0-aiirok7 hwloc/2.5.0/gcc-9.4.0-7sqomga
    libevent/2.1.12/gcc-9.4.0-hgny7cm numactl/2.0.14/gcc-9.4.0-52dwc6n
    cuda/11.4.0/gcc-9.4.0-3hnxhjt gdrcopy/2.2/gcc-9.4.0-e4igtfp
    knem/1.1.4/gcc-9.4.0-bpbxgva libnl/3.3.0/gcc-9.4.0-whwhrwb
    rdma-core/34.0/gcc-9.4.0-5eo5n2u ucx/1.11.1/gcc-9.4.0-lktqyl4
    openmpi/4.1.1/gcc-9.4.0-epagguv
Changed directory to /home/er647/projects/feature-wise-active-learning.

JobID: 43007333
======
Time: Fri Jan 26 02:52:50 GMT 2024
Running on master node: gpu-q-80
Current directory: /home/er647/projects/feature-wise-active-learning

Nodes allocated:
================
gpu-q-80

numtasks=4, numnodes=1, mpi_tasks_per_node=4 (OMP_NUM_THREADS=1)

Executing command:
==================
wandb agent evangeorgerex/fwal/hy72bous

wandb: Starting wandb agent üïµÔ∏è
2024-01-26 02:53:01,284 - wandb.wandb_agent - INFO - Running runs: []
2024-01-26 02:53:01,621 - wandb.wandb_agent - INFO - Agent received command: run
2024-01-26 02:53:01,621 - wandb.wandb_agent - INFO - Agent starting run with config:
	dataset: simple_trig_synth
	mask_init_value: -1
	mask_type: gumbel_softmax
	repeat_id: 0
	seed_model_init: 0
2024-01-26 02:53:01,627 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python /home/er647/projects/feature-wise-active-learning/src/run_experiment.py --model fwal --valid_percentage 0.25 --sparsity_type global --gamma 1 --sparsity_regularizer L1 --sparsity_regularizer_hyperparam 1 --test_time_interventions evaluate_test_time_interventions --hpc_run --num_workers 31 --tags c50d3bf6 --notes "Comparing different constant mask initialisations. Gumbel and Softmax. All 5 datasets. x3 test splits x3 weight inits" --dataset=simple_trig_synth --mask_init_value=-1 --mask_type=gumbel_softmax --repeat_id=0 --seed_model_init=0
2024-01-26 02:53:06,641 - wandb.wandb_agent - INFO - Running runs: ['9yr5kwln']
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
wandb: Currently logged in as: evangeorgerex. Use `wandb login --relogin` to force relogin
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.16.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.1
wandb: Run data is saved locally in ./wandb/run-20240126_025322-9yr5kwln
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run serene-sweep-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/evangeorgerex/fwal
wandb: üßπ View sweep at https://wandb.ai/evangeorgerex/fwal/sweeps/hy72bous
wandb: üöÄ View run at https://wandb.ai/evangeorgerex/fwal/runs/9yr5kwln
wandb: WARNING Config item 'dataset' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'mask_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'repeat_id' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'seed_model_init' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'mask_init_value' was locked by 'sweep' (ignored update).
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[rank: 0] Seed set to 0
[rank: 0] Seed set to 42
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[rank: 0] Seed set to 42
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

slurmstepd: error: *** JOB 43007333 ON gpu-q-80 CANCELLED AT 2024-01-26T12:03:43 ***
