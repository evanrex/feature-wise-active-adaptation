@article{tree_based_tabular,
 author = {Grinsztajn, L{\'e}o and Oyallon, Edouard and Varoquaux, Ga{\"e}l},
 journal = {Advances in Neural Information Processing Systems},
 pages = {507--520},
 title = {Why do tree-based models still outperform deep learning on typical tabular data?},
 volume = {35},
 year = {2022}
}

@article{Active_Learning,
 author = {Settles, Burr},
 journal = {Science},
 number = {3},
 pages = {237--304},
 publisher = {University of Wisconsin--Madison},
 title = {Active Learning Literature Survey},
 volume = {10},
 year = {1995}
}

@inproceedings{WPFS,
 author = {Margeloiu, Andrei and Simidjievski, Nikola and Lio, Pietro and Jamnik, Mateja},
 booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
 pages = {9081--9089},
 title = {Weight predictor network with feature selection for small sample tabular biomedical data},
 volume = {37},
 year = {2023}
}

@inproceedings{
jiang2023protogate,
title={ProtoGate: Prototype-based Neural Networks with Local Feature Selection for Tabular Biomedical Data},
author={Xiangjian Jiang and Andrei Margeloiu and Nikola Simidjievski and Mateja Jamnik},
booktitle={ICML 3rd Workshop on Interpretable Machine Learning in Healthcare (IMLH) },
year={2023},
url={https://openreview.net/forum?id=d0hmveMhSK}
}


@inproceedings{SEFS,
 author = {Lee, Changhee and Imrie, Fergus and van der Schaar, Mihaela},
 booktitle = {International Conference on Learning Representations},
 title = {Self-supervision enhanced feature selection with correlated gates},
 year = {2021}
}

@inproceedings{CBM,
 author = {Pang Wei Koh and
Thao Nguyen and
Yew Siang Tang and
Stephen Mussmann and
Emma Pierson and
Been Kim and
Percy Liang},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/icml/KohNTMPKL20.bib},
 booktitle = {Proceedings of the 37th International Conference on Machine Learning,
{ICML} 2020, 13-18 July 2020, Virtual Event},
 pages = {5338--5348},
 publisher = {{PMLR}},
 series = {Proceedings of Machine Learning Research},
 timestamp = {Tue, 15 Dec 2020 00:00:00 +0100},
 title = {Concept Bottleneck Models},
 url = {http://proceedings.mlr.press/v119/koh20a.html},
 volume = {119},
 year = {2020}
}

@article{CEM,
 author = {Espinosa Zarlenga, Mateo and Barbiero, Pietro and Ciravegna, Gabriele and Marra, Giuseppe and Giannini, Francesco and Diligenti, Michelangelo and Shams, Zohreh and Precioso, Frederic and Melacci, Stefano and Weller, Adrian and others},
 journal = {Advances in Neural Information Processing Systems},
 pages = {21400--21413},
 title = {Concept embedding models: Beyond the accuracy-explainability trade-off},
 volume = {35},
 year = {2022}
}

@article{Imputation_Review,
 author = {KohbalanMoorthy, Mohammed Hasan Ali and MohdArfianIsmail, Chan Weng Howe and MohdSaberiMohamad, SafaaiDeris},
 journal = {InternationalJournal of Innovative Technology and Exploring Engineering},
 pages = {415--420},
 title = {An evaluation of machine learning algorithms for missing values imputation},
 volume = {8},
 year = {2019}
}

@article{Feature_Selection_for_Incomplete_Data,
 author = {Cai, Jun and Fan, Linge and Xu, Xin and Wu, Xinrong},
 journal = {Applied Sciences},
 number = {17},
 pages = {8752},
 publisher = {MDPI},
 title = {Unsupervised and Supervised Feature Selection for Incomplete Data via L2, 1-Norm and Reconstruction Error Minimization},
 volume = {12},
 year = {2022}
}

@inproceedings{c86b81c9231b4414be4b3df12fe2f0b7,
title = "The Shapley Value in Machine Learning",
abstract = "Over the last few years, the Shapley value, a solution concept from cooperative game theory, has found numerous applications in machine learning. In this paper, we first discuss fundamental concepts of cooperative game theory and axiomatic properties of the Shapley value. Then we give an overview of the most important applications of the Shapley value in machine learning: feature selection, explainability, multi-agent reinforcement learning, ensemble pruning, and data valuation. We examine the most crucial limitations of the Shapley value and point out directions for future research.",
author = "Benedek Rozemberczki and Lauren Watson and P{\'e}ter Bayer and Hao-Tsung Yang and Oliv{\'e}r Kiss and Sebastian Nilsson and Rik Sarkar",
year = "2022",
month = jul,
day = "23",
doi = "10.24963/ijcai.2022/778",
language = "English",
isbn = "978-1-956792-00-3",
pages = "5572--5579",
editor = "{De Raedt}, Luc",
booktitle = "Proceedings of the 31st International Joint Conference on Artifical Intelligence, IJCAI-ECAI 2022",
publisher = "International Joint Conferences on Artificial Intelligence Organization",
note = "The 31st International Joint Conference on Artificial Intelligence and the 25th European Conference on Artificial Intelligence, IJCAI-ECAI 2022 ; Conference date: 23-07-2022 Through 29-07-2022",
url = "https://ijcai-22.org/",
}

@inproceedings{FIRM,
 author = {Zien, Alexander and Kr{\"a}mer, Nicole and Sonnenburg, S{\"o}ren and R{\"a}tsch, Gunnar},
 booktitle = {Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2009, Bled, Slovenia, September 7-11, 2009, Proceedings, Part II 20},
 organization = {Springer},
 pages = {694--709},
 title = {The feature importance ranking measure},
 year = {2009}
}

@article{feature_selection_based_importance,
 author = {Wei, Guangfen and Zhao, Jie and Feng, Yanli and He, Aixiang and Yu, Jun},
 journal = {Applied Soft Computing},
 pages = {106337},
 publisher = {Elsevier},
 title = {A novel hybrid feature selection method based on dynamic feature importance},
 volume = {93},
 year = {2020}
}

@inproceedings{Evaluating_feature_importance,
 author = {Sara Hooker and
Dumitru Erhan and
Pieter{-}Jan Kindermans and
Been Kim},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/nips/HookerEKK19.bib},
 booktitle = {Advances in Neural Information Processing Systems 32: Annual Conference
on Neural Information Processing Systems 2019, NeurIPS 2019, December
8-14, 2019, Vancouver, BC, Canada},
 editor = {Hanna M. Wallach and
Hugo Larochelle and
Alina Beygelzimer and
Florence d'Alch{\'{e}}{-}Buc and
Emily B. Fox and
Roman Garnett},
 pages = {9734--9745},
 timestamp = {Thu, 21 Jan 2021 00:00:00 +0100},
 title = {A Benchmark for Interpretability Methods in Deep Neural Networks},
 url = {https://proceedings.neurips.cc/paper/2019/hash/fe4b8556000d0f0cae99daa5c5c5a410-Abstract.html},
 year = {2019}
}

@article{NeuMiss,
 author = {Le Morvan, Marine and Josse, Julie and Moreau, Thomas and Scornet, Erwan and Varoquaux, Ga{\"e}l},
 journal = {Advances in Neural Information Processing Systems},
 pages = {5980--5990},
 title = {NeuMiss networks: differentiable programming for supervised learning with missing values.},
 volume = {33},
 year = {2020}
}

@article{Beyond-Impute-Then-Regress,
 author = {Bertsimas, Dimitris and Delarue, Arthur and Pauphilet, Jean},
 journal = {ArXiv preprint},
 title = {Beyond impute-then-regress: Adapting prediction to missing data},
 url = {https://arxiv.org/abs/2104.03158},
 volume = {abs/2104.03158},
 year = {2021}
}


@InProceedings{pmlr-v97-balin19a,
  title = 	 {Concrete Autoencoders: Differentiable Feature Selection and Reconstruction},
  author =       {Bal{\i}n, Muhammed Fatih and Abid, Abubakar and Zou, James},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {444--453},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/balin19a/balin19a.pdf},
  url = 	 {https://proceedings.mlr.press/v97/balin19a.html},
  abstract = 	 {We introduce the concrete autoencoder, an end-to-end differentiable method for global feature selection, which efficiently identifies a subset of the most informative features and simultaneously learns a neural network to reconstruct the input data from the selected features. Our method is unsupervised, and is based on using a concrete selector layer as the encoder and using a standard neural network as the decoder. During the training phase, the temperature of the concrete selector layer is gradually decreased, which encourages a user-specified number of discrete features to be learned; during test time, the selected features can be used with the decoder network to reconstruct the remaining input features. We evaluate concrete autoencoders on a variety of datasets, where they significantly outperform state-of-the-art methods for feature selection and data reconstruction. In particular, on a large-scale gene expression dataset, the concrete autoencoder selects a small subset of genes whose expression levels can be used to impute the expression levels of the remaining genes; in doing so, it improves on the current widely-used expert-curated L1000 landmark genes, potentially reducing measurement costs by 20%. The concrete autoencoder can be implemented by adding just a few lines of code to a standard autoencoder, and the code for the algorithm and experiments is publicly available.}
}


@article{madelon_features,
 author = {Piliszek, Radoslaw and Mnich, Krzysztof and Migacz, Szymon and Tabaszewski, Pawel and Sulecki, Andrzej and Polewko-Klim, Aneta and Rudnicki, Witold R},
 journal = {R J.},
 number = {1},
 pages = {198},
 title = {MDFS: MultiDimensional Feature Selection in R.},
 volume = {11},
 year = {2019}
}

@article{PBMC,
 author = {Gayoso, Adam and Steier, Zo{\"e} and Lopez, Romain and Regier, Jeffrey and Nazor, Kristopher L and Streets, Aaron and Yosef, Nir},
 journal = {Biorxiv},
 pages = {2020--05},
 publisher = {Cold Spring Harbor Laboratory},
 title = {Joint probabilistic modeling of paired transcriptome and proteome measurements in single cells},
 year = {2020}
}

@article{ASU_datasets,
 author = {Li, Jundong and Cheng, Kewei and Wang, Suhang and Morstatter, Fred and Trevino, Robert P and Tang, Jiliang and Liu, Huan},
 journal = {ACM Computing Surveys (CSUR)},
 number = {6},
 pages = {94},
 publisher = {ACM},
 title = {Feature selection: A data perspective},
 volume = {50},
 year = {2018}
}

@techreport{Nene1996COIL20,
 author = {Nene, Shree K. and Nayar, Shree K. and Murase, Hiroshi},
 institution = {Columbia University},
 number = {CUCS-005-96},
 title = {Columbia Object Image Library (COIL-20)},
 year = {1996}
}

@article{Hull1994USPS,
 author = {Hull, Jonathan J.},
 journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
 number = {5},
 pages = {550--554},
 publisher = {IEEE},
 title = {A database for handwritten text recognition research},
 volume = {16},
 year = {1994}
}

@misc{misc_isolet_54,
 author = {Cole,Ron and Fanty,Mark},
 howpublished = {UCI Machine Learning Repository},
 note = {{DOI}: https://doi.org/10.24432/C51G69},
 title = {{ISOLET}},
 year = {1994}
}

@article{USPS_COIL20_Isolet_1,
 author = {Cai, Deng and He, Xiaofei and Han, Jiawei and Huang, Thomas S},
 journal = {IEEE transactions on pattern analysis and machine intelligence},
 number = {8},
 pages = {1548--1560},
 publisher = {IEEE},
 title = {Graph regularized nonnegative matrix factorization for data representation},
 volume = {33},
 year = {2010}
}

@article{USPS_COIL20_Isolet_2,
 author = {Cai, Deng and He, Xiaofei and Han, Jiawei},
 journal = {The VLDB Journal},
 pages = {21--33},
 publisher = {Springer},
 title = {Speed up kernel discriminant analysis},
 volume = {20},
 year = {2011}
}

@misc{madelon,
 author = {Guyon,Isabelle},
 howpublished = {UCI Machine Learning Repository},
 note = {{DOI}: https://doi.org/10.24432/C5602H},
 title = {{Madelon}},
 year = {2008}
}

@data{finance,
 author = {Nicolas Carbone},
 title = {200+ Financial Indicators of US stocks (2014-2018)},
 url = {https://www.kaggle.com/datasets/cnic92/200-financial-indicators-of-us-stocks-20142018},
 urldate = {2024-05-23},
 version = {2014},
 year = {2020}
}

@article{lasso,
 author = {Robert Tibshirani},
 journal = {Journal of the Royal Statistical Society, Series B},
 number = {1},
 pages = {267--288},
 title = {Regression Shrinkage and Selection via the Lasso},
 volume = {58},
 year = {1996}
}

@inproceedings{loshchilov2017decoupled,
 author = {Ilya Loshchilov and
Frank Hutter},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/iclr/LoshchilovH19.bib},
 booktitle = {7th International Conference on Learning Representations, {ICLR} 2019,
New Orleans, LA, USA, May 6-9, 2019},
 publisher = {OpenReview.net},
 timestamp = {Thu, 25 Jul 2019 01:00:00 +0200},
 title = {Decoupled Weight Decay Regularization},
 url = {https://openreview.net/forum?id=Bkg6RiCqY7},
 year = {2019}
}

@article{random_forest,
 author = {Leo Breiman},
 journal = {Machine Learning},
 number = {1},
 pages = {5--32},
 title = {Random Forests},
 volume = {45},
 year = {2001}
}

@article{zou2005regularization,
 author = {Zou, Hui and Hastie, Trevor},
 journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
 number = {2},
 pages = {301--320},
 publisher = {Oxford University Press},
 title = {Regularization and variable selection via the elastic net},
 volume = {67},
 year = {2005}
}

@inproceedings{xgboost,
 author = {Tianqi Chen and
Carlos Guestrin},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/kdd/ChenG16.bib},
 booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} International Conference on
Knowledge Discovery and Data Mining, San Francisco, CA, USA, August
13-17, 2016},
 doi = {10.1145/2939672.2939785},
 editor = {Balaji Krishnapuram and
Mohak Shah and
Alexander J. Smola and
Charu C. Aggarwal and
Dou Shen and
Rajeev Rastogi},
 pages = {785--794},
 publisher = {{ACM}},
 timestamp = {Sun, 02 Jun 2019 01:00:00 +0200},
 title = {XGBoost: {A} Scalable Tree Boosting System},
 url = {https://doi.org/10.1145/2939672.2939785},
 year = {2016}
}


@InProceedings{pmlr-v162-jarrett22a,
  title = 	 {{H}yper{I}mpute: Generalized Iterative Imputation with Automatic Model Selection},
  author =       {Jarrett, Daniel and Cebere, Bogdan C and Liu, Tennison and Curth, Alicia and van der Schaar, Mihaela},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {9916--9937},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/jarrett22a/jarrett22a.pdf},
  url = 	 {https://proceedings.mlr.press/v162/jarrett22a.html},
  abstract = 	 {Consider the problem of imputing missing values in a dataset. One the one hand, conventional approaches using iterative imputation benefit from the simplicity and customizability of learning conditional distributions directly, but suffer from the practical requirement for appropriate model specification of each and every variable. On the other hand, recent methods using deep generative modeling benefit from the capacity and efficiency of learning with neural network function approximators, but are often difficult to optimize and rely on stronger data assumptions. In this work, we study an approach that marries the advantages of both: We propose *HyperImpute*, a generalized iterative imputation framework for adaptively and automatically configuring column-wise models and their hyperparameters. Practically, we provide a concrete implementation with out-of-the-box learners, optimizers, simulators, and extensible interfaces. Empirically, we investigate this framework via comprehensive experiments and sensitivities on a variety of public datasets, and demonstrate its ability to generate accurate imputations relative to a strong suite of benchmarks. Contrary to recent work, we believe our findings constitute a strong defense of the iterative imputation paradigm.}
}


@book{imputation,
 author = {Roderick J. A. Little and Donald B. Rubin},
 edition = {2},
 publisher = {John Wiley \& Sons},
 title = {Statistical Analysis with Missing Data},
 year = {2002}
}

@article{ice,
 author = {Stef van Buuren},
 journal = {Statistical Methods in Medical Research},
 number = {3},
 pages = {219--242},
 title = {Multiple imputation of discrete and continuous data by fully conditional specification},
 volume = {16},
 year = {2007}
}

@article{missforest,
 author = {Daniel J. Stekhoven and Peter Bühlmann},
 journal = {Bioinformatics},
 number = {1},
 pages = {112--118},
 publisher = {Oxford University Press},
 title = {MissForest--non-parametric missing value imputation for mixed-type data},
 volume = {28},
 year = {2012}
}

@article{MLP,
 author = {David E. Rumelhart and Geoffrey E. Hinton and Ronald J. Williams},
 journal = {Nature},
 number = {6088},
 pages = {533--536},
 title = {Learning representations by back-propagating errors},
 volume = {323},
 year = {1986}
}

@article{learningtoreivehelp,
 author = {Espinosa Zarlenga, Mateo and Collins, Katie and Dvijotham, Krishnamurthy and Weller, Adrian and Shams, Zohreh and Jamnik, Mateja},
 journal = {Advances in Neural Information Processing Systems},
 title = {Learning to Receive Help: Intervention-Aware Concept Embedding Models},
 volume = {36},
 year = {2024}
}

@article{feature_selection_review,
 author = {Bol{\'o}n-Canedo, Ver{\'o}nica and S{\'a}nchez-Maro{\~n}o, Noelia and Alonso-Betanzos, Amparo},
 journal = {Knowledge and information systems},
 pages = {483--519},
 publisher = {Springer},
 title = {A review of feature selection methods on synthetic data},
 volume = {34},
 year = {2013}
}

@inproceedings{melville2004active,
 author = {Melville, Prem and Saar-Tsechansky, Maytal and Provost, Foster and Mooney, Raymond},
 booktitle = {Fourth IEEE International Conference on Data Mining (ICDM'04)},
 organization = {IEEE},
 pages = {483--486},
 title = {Active feature-value acquisition for classifier induction},
 year = {2004}
}

@article{saar2009active,
 author = {Saar-Tsechansky, Maytal and Melville, Prem and Provost, Foster},
 journal = {Management Science},
 number = {4},
 pages = {664--684},
 publisher = {INFORMS},
 title = {Active feature-value acquisition},
 volume = {55},
 year = {2009}
}

@inproceedings{pmlr-v139-li21p,
 author = {Li, Yang and Oliva, Junier},
 booktitle = {Proceedings of the 38th International Conference on Machine Learning},
 editor = {Meila, Marina and Zhang, Tong},
 pages = {6450--6459},
 pdf = {http://proceedings.mlr.press/v139/li21p/li21p.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Active Feature Acquisition with Generative Surrogate Models},
 url = {https://proceedings.mlr.press/v139/li21p.html},
 volume = {139},
 year = {2021}
}

@inproceedings{shim2018joint,
 author = {Hajin Shim and
Sung Ju Hwang and
Eunho Yang},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/nips/ShimHY18.bib},
 booktitle = {Advances in Neural Information Processing Systems 31: Annual Conference
on Neural Information Processing Systems 2018, NeurIPS 2018, December
3-8, 2018, Montr{\'{e}}al, Canada},
 editor = {Samy Bengio and
Hanna M. Wallach and
Hugo Larochelle and
Kristen Grauman and
Nicol{\`{o}} Cesa{-}Bianchi and
Roman Garnett},
 pages = {1375--1385},
 timestamp = {Thu, 21 Jan 2021 00:00:00 +0100},
 title = {Joint Active Feature Acquisition and Classification with Variable-Size
Set Encoding},
 url = {https://proceedings.neurips.cc/paper/2018/hash/e5841df2166dd424a57127423d276bbe-Abstract.html},
 year = {2018}
}

@inproceedings{li2021active,
 author = {Li, Yang and Oliva, Junier},
 booktitle = {International Conference on Machine Learning},
 organization = {PMLR},
 pages = {6450--6459},
 title = {Active feature acquisition with generative surrogate models},
 year = {2021}
}

@inproceedings{pmlr-v202-covert23a,
 author = {Covert, Ian Connick and Qiu, Wei and Lu, Mingyu and Kim, Na Yoon and White, Nathan J and Lee, Su-In},
 booktitle = {Proceedings of the 40th International Conference on Machine Learning},
 editor = {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
 pages = {6424--6447},
 pdf = {https://proceedings.mlr.press/v202/covert23a/covert23a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {Learning to Maximize Mutual Information for Dynamic Feature Selection},
 url = {https://proceedings.mlr.press/v202/covert23a.html},
 volume = {202},
 year = {2023}
}

@inproceedings{buttner2023joining,
 author = {B{\"u}ttner, Maik and Beyer, Christian and Spiliopoulou, Myra},
 booktitle = {International Conference on Discovery Science},
 organization = {Springer},
 pages = {308--322},
 title = {Joining Imputation and Active Feature Acquisition for Cost Saving on Data Streams with Missing Features},
 year = {2023}
}

@inproceedings{afa_training,
 author = {Melville, P. and Saar-Tsechansky, M. and Provost, F. and Mooney, R.},
 booktitle = {Fourth IEEE International Conference on Data Mining (ICDM'04)},
 doi = {10.1109/ICDM.2004.10075},
 keywords = {Costs;Predictive models;Sampling methods;Design for experiments;Current measurement;Data mining},
 number = {},
 pages = {483-486},
 title = {Active feature-value acquisition for classifier induction},
 volume = {},
 year = {2004}
}

@article{feature_redundancy,
 author = {Peng, Hanchuan and Long, Fuhui and Ding, Chris},
 journal = {IEEE Transactions on pattern analysis and machine intelligence},
 number = {8},
 pages = {1226--1238},
 publisher = {IEEE},
 title = {Feature selection based on mutual information criteria of max-dependency, max-relevance, and min-redundancy},
 volume = {27},
 year = {2005}
}

@article{von2022evaluation,
 author = {von Kleist, Henrik and Zamanian, Alireza and Shpitser, Ilya and Ahmidi, Narges},
 title = {Evaluation of Active Feature Acquisition Methods under Missing Data},
 year = {2022}
}

@article{filter1,
 author = {Peng, Hanchuan and Long, Fuhui and Ding, Chris},
 journal = {IEEE Transactions on pattern analysis and machine intelligence},
 number = {8},
 pages = {1226--1238},
 publisher = {IEEE},
 title = {Feature selection based on mutual information criteria of max-dependency, max-relevance, and min-redundancy},
 volume = {27},
 year = {2005}
}

@article{filter2,
 author = {Guyon, Isabelle and Elisseeff, Andr{\'e}},
 journal = {Journal of machine learning research},
 number = {Mar},
 pages = {1157--1182},
 title = {An introduction to variable and feature selection},
 volume = {3},
 year = {2003}
}

@article{wrapper1,
 author = {Kohavi, Ron and John, George H},
 journal = {Artificial intelligence},
 number = {1-2},
 pages = {273--324},
 publisher = {Elsevier},
 title = {Wrappers for feature subset selection},
 volume = {97},
 year = {1997}
}

@article{elasticnet,
 author = {Zou, Hui and Hastie, Trevor},
 journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
 number = {2},
 pages = {301--320},
 publisher = {Oxford University Press},
 title = {Regularization and variable selection via the elastic net},
 volume = {67},
 year = {2005}
}

@article{imputation_feature_selection1,
 abstract = {The presence of missing values in real-world data is not only a prevalent problem but also an inevitable one. Therefore, missing values should be handled carefully before the mining or learning process. This paper proposes a novel technique to impute missing data. It employs a new version of Fuzzy c-Means clustering algorithm which benefits from advantages of Grey Relational Grade over Minkowski-like similarity measures. To impute a missing value more accurately, it also performs a local mutual information based feature selection in each cluster to select only highly relevant features. Briefly, missing values are imputed in the following steps. First, the algorithm finds the importance of each missing attribute. Next, input instances are separated into several fuzzy clusters. Then, the algorithm selects clusters which satisfy a minimum condition. After that, it chooses highly dependent features of instances within each cluster using a mutual information based feature selection approach. When the features are selected, regression models will be applied to the selected features of the selected clusters to provide estimations for a missing value. Finally, the missing value is imputed through a weighted average of estimated values obtained from the previous step. Three well-known evaluation criteria and the accuracy of classification task are used to assess the performance of the proposed method. The experimental results for seven UCI data sets with different missing ratios and strategies indicate that the proposed algorithm outperforms five other imputation methods in general.},
 author = {Amir Masoud Sefidian and Negin Daneshpour},
 doi = {https://doi.org/10.1016/j.eswa.2018.07.057},
 issn = {0957-4174},
 journal = {Expert Systems with Applications},
 keywords = {Missing data imputation, Grey relational analysis, Fuzzy c-means, Mutual information, Regression},
 pages = {68-94},
 title = {Missing value imputation using a novel grey based fuzzy c-means, mutual information based feature selection, and regression model},
 url = {https://www.sciencedirect.com/science/article/pii/S0957417418304822},
 volume = {115},
 year = {2019}
}

@article{imputation_feature_selection2,
 author = {Doquire, Gauthier and Verleysen, Michel},
 journal = {Neurocomputing},
 pages = {3--11},
 publisher = {Elsevier},
 title = {Feature selection with missing data using mutual information estimators},
 volume = {90},
 year = {2012}
}

@inproceedings{imputation_feature_selection3,
 author = {Meesad, Phayung and Hengpraprohm, Kairung},
 booktitle = {2008 3rd International Conference on Innovative Computing Information and Control},
 doi = {10.1109/ICICIC.2008.635},
 keywords = {Estimation;Tumors;Distance measurement;Gene expression;Cancer;Lungs;DNA},
 number = {},
 pages = {341-341},
 title = {Combination of KNN-Based Feature Selection and KNNBased Missing-Value Imputation of Microarray Data},
 volume = {},
 year = {2008}
}

@article{PBMC_weatherly,
 author = {Weatherly, Kathleen and Bettonville, Marie and Torres, David and Kohler, Arnaud and Goriely, Stanislas and Braun, Michel Y},
 journal = {Immunity, inflammation and disease},
 number = {4},
 pages = {431--444},
 publisher = {Wiley Online Library},
 title = {Functional profile of S100A4-deficient T cells},
 volume = {3},
 year = {2015}
}

@article{PBMC_goda,
 author = {Goda, Chiho and Kanaji, Taisuke and Kanaji, Sachiko and Tanaka, Go and Arima, Kazuhiko and Ohno, Shigeaki and Izuhara, Kenji},
 journal = {International immunology},
 number = {2},
 pages = {233--240},
 publisher = {Oxford University Press},
 title = {Involvement of IL-32 in activation-induced cell death in T cells},
 volume = {18},
 year = {2006}
}

@article{PBMC_zhang,
 author = {Zhang, Yongliang and Reynolds, Joseph M and Chang, Seon Hee and Martin-Orozco, Natalia and Chung, Yeonseok and Nurieva, Roza I and Dong, Chen},
 journal = {Journal of biological chemistry},
 number = {45},
 pages = {30815--30824},
 publisher = {ASBMB},
 title = {MKP-1 is necessary for T cell activation and function},
 volume = {284},
 year = {2009}
}

@article{mice_explained,
 author = {Azur, Melissa J and Stuart, Elizabeth A and Frangakis, Constantine and Leaf, Philip J},
 journal = {International journal of methods in psychiatric research},
 number = {1},
 pages = {40--49},
 publisher = {Wiley Online Library},
 title = {Multiple imputation by chained equations: what is it and how does it work?},
 volume = {20},
 year = {2011}
}

@inproceedings{deep_learning,
 author = {Ruslan Salakhutdinov},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/kdd/Salakhutdinov14.bib},
 booktitle = {The 20th {ACM} {SIGKDD} International Conference on Knowledge Discovery
and Data Mining, {KDD} '14, New York, NY, {USA} - August 24 - 27,
2014},
 doi = {10.1145/2623330.2630809},
 editor = {Sofus A. Macskassy and
Claudia Perlich and
Jure Leskovec and
Wei Wang and
Rayid Ghani},
 pages = {1973},
 publisher = {{ACM}},
 timestamp = {Tue, 06 Nov 2018 00:00:00 +0100},
 title = {Deep learning},
 url = {https://doi.org/10.1145/2623330.2630809},
 year = {2014}
}

@article{mice_pitfalls,
 author = {White, Ian R and Royston, Patrick and Wood, Angela M},
 journal = {Statistics in medicine},
 number = {4},
 pages = {377--399},
 publisher = {Wiley Online Library},
 title = {Multiple imputation using chained equations: issues and guidance for practice},
 volume = {30},
 year = {2011}
}

@inproceedings{kingma2014adam,
 author = {Diederik P. Kingma and
Jimmy Ba},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/journals/corr/KingmaB14.bib},
 booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
 editor = {Yoshua Bengio and
Yann LeCun},
 timestamp = {Thu, 25 Jul 2019 01:00:00 +0200},
 title = {Adam: {A} Method for Stochastic Optimization},
 url = {http://arxiv.org/abs/1412.6980},
 year = {2015}
}

@inproceedings{gumbel_softmax,
 author = {Eric Jang and
Shixiang Gu and
Ben Poole},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/iclr/JangGP17.bib},
 booktitle = {5th International Conference on Learning Representations, {ICLR} 2017,
Toulon, France, April 24-26, 2017, Conference Track Proceedings},
 publisher = {OpenReview.net},
 timestamp = {Thu, 25 Jul 2019 01:00:00 +0200},
 title = {Categorical Reparameterization with Gumbel-Softmax},
 url = {https://openreview.net/forum?id=rkE3y85ee},
 year = {2017}
}

@book{hastie2009elements,
 author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome H and Friedman, Jerome H},
 publisher = {Springer},
 title = {The elements of statistical learning: data mining, inference, and prediction},
 volume = {2},
 year = {2009}
}

@article{le2021sa,
 author = {Le Morvan, Marine and Josse, Julie and Scornet, Erwan and Varoquaux, Ga{\"e}l},
 journal = {Advances in Neural Information Processing Systems},
 pages = {11530--11540},
 title = {What’sa good imputation to predict with missing values?},
 volume = {34},
 year = {2021}
}

@article{kohbalanmoorthy2019evaluation,
 author = {KohbalanMoorthy, Mohammed HasanAli and MohdArfianIsmail, Chan Weng Howe and MohdSaber Mohamad, SafaaiDeris},
 journal = {Internationa Journal of Innovative Technology and Exploring Engineering (IJITEE)},
 pages = {415--420},
 title = {An Evaluation of Machine Learning Algorithms for Missing Values Imputation},
 volume = {8},
 year = {2019}
}

@inproceedings{thirukumaran2012missing,
 author = {Thirukumaran, S and Sumathi, A},
 booktitle = {2012 Fourth International Conference on Advanced Computing (ICoAC)},
 organization = {IEEE},
 pages = {1--5},
 title = {Missing value imputation techniques depth survey and an imputation algorithm to improve the efficiency of imputation},
 year = {2012}
}

@article{post_training_hyperparam_tuning,
 author = {Tian, Junjiao and Liu, Yen-Cheng and Glaser, Nathaniel and Hsu, Yen-Chang and Kira, Zsolt},
 journal = {Advances in neural information processing systems},
 pages = {8101--8113},
 title = {Posterior re-calibration for imbalanced datasets},
 volume = {33},
 year = {2020}
}

@inproceedings{chen2020self,
 author = {Yining Chen and
Colin Wei and
Ananya Kumar and
Tengyu Ma},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/nips/ChenWKM20.bib},
 booktitle = {Advances in Neural Information Processing Systems 33: Annual Conference
on Neural Information Processing Systems 2020, NeurIPS 2020, December
6-12, 2020, virtual},
 editor = {Hugo Larochelle and
Marc'Aurelio Ranzato and
Raia Hadsell and
Maria{-}Florina Balcan and
Hsuan{-}Tien Lin},
 timestamp = {Tue, 19 Jan 2021 00:00:00 +0100},
 title = {Self-training Avoids Using Spurious Features Under Domain Shift},
 url = {https://proceedings.neurips.cc/paper/2020/hash/f1298750ed09618717f9c10ea8d1d3b0-Abstract.html},
 year = {2020}
}

@article{overfitting_hdlss,
 author = {Subramanian, Jyothi and Simon, Richard},
 journal = {Contemporary clinical trials},
 number = {2},
 pages = {636--641},
 publisher = {Elsevier},
 title = {Overfitting in prediction models--is it a problem only in high dimensions?},
 volume = {36},
 year = {2013}
}

@article{borisov2022deep,
 author = {Borisov, Vadim and Leemann, Tobias and Se{\ss}ler, Kathrin and Haug, Johannes and Pawelczyk, Martin and Kasneci, Gjergji},
 journal = {IEEE Transactions on Neural Networks and Learning Systems},
 publisher = {IEEE},
 title = {Deep neural networks and tabular data: A survey},
 year = {2022}
}

@article{grosse2021cost,
 author = {Grosse, Scott D and Gudgeon, James M},
 journal = {Genetics in Medicine},
 number = {10},
 pages = {1833--1835},
 publisher = {Nature Publishing Group US New York},
 title = {Cost or price of sequencing? Implications for economic evaluations in genomic medicine},
 volume = {23},
 year = {2021}
}

@book{bishop2006pattern,
 author = {Bishop, Christopher M},
 publisher = {Springer},
 title = {Pattern Recognition and Machine Learning},
 year = {2006}
}

@article{hoerl1970ridge,
 author = {Hoerl, Arthur E and Kennard, Robert W},
 journal = {Technometrics},
 number = {1},
 pages = {55--67},
 publisher = {Taylor \& Francis},
 title = {Ridge regression: Biased estimation for nonorthogonal problems},
 volume = {12},
 year = {1970}
}

@incollection{chemmanam2022joint,
 author = {Chemmanam, Ajai John and Jose, Bijoy A},
 booktitle = {Responsible Data Science: Select Proceedings of ICDSE 2021},
 pages = {155--167},
 publisher = {Springer},
 title = {Joint learning for multitasking models},
 year = {2022}
}

@article{Cybenko1989Approximation,
 author = {Cybenko, George},
 journal = {Mathematics of Control, Signals, and Systems},
 number = {4},
 pages = {303--314},
 publisher = {Springer},
 title = {Approximation by superpositions of a sigmoidal function},
 volume = {2},
 year = {1989}
}

@article{Hornik1991Approximation,
 author = {Hornik, Kurt},
 journal = {Neural Networks},
 number = {2},
 pages = {251--257},
 publisher = {Elsevier},
 title = {Approximation capabilities of multilayer feedforward networks},
 volume = {4},
 year = {1991}
}

@inproceedings{guyon2004result,
 author = {Isabelle Guyon and
Steve R. Gunn and
Asa Ben{-}Hur and
Gideon Dror},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/nips/GuyonGBD04.bib},
 booktitle = {Advances in Neural Information Processing Systems 17 [Neural Information
Processing Systems, {NIPS} 2004, December 13-18, 2004, Vancouver,
British Columbia, Canada]},
 pages = {545--552},
 timestamp = {Thu, 21 Jan 2021 00:00:00 +0100},
 title = {Result Analysis of the {NIPS} 2003 Feature Selection Challenge},
 url = {https://proceedings.neurips.cc/paper/2004/hash/5e751896e527c862bf67251a474b3819-Abstract.html},
 year = {2004}
}

@article{gayoso2022python,
 author = {Gayoso, Adam and Lopez, Romain and Xing, Galen and Boyeau, Pierre and Valiollah Pour Amiri, Valeh and Hong, Justin and Wu, Katherine and Jayasuriya, Michael and Mehlman, Edouard and Langevin, Maxime and others},
 journal = {Nature biotechnology},
 number = {2},
 pages = {163--166},
 publisher = {Nature Publishing Group},
 title = {A Python library for probabilistic analysis of single-cell omics data},
 volume = {40},
 year = {2022}
}

@misc{wandb,
 author = {Biewald, Lukas},
 note = {Software available from wandb.com},
 title = {Experiment Tracking with Weights and Biases},
 url = {https://www.wandb.com/},
 year = {2020}
}

@inproceedings{paszke2019pytorch,
 author = {Adam Paszke and
Sam Gross and
Francisco Massa and
Adam Lerer and
James Bradbury and
Gregory Chanan and
Trevor Killeen and
Zeming Lin and
Natalia Gimelshein and
Luca Antiga and
Alban Desmaison and
Andreas K{\"{o}}pf and
Edward Yang and
Zachary DeVito and
Martin Raison and
Alykhan Tejani and
Sasank Chilamkurthy and
Benoit Steiner and
Lu Fang and
Junjie Bai and
Soumith Chintala},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/nips/PaszkeGMLBCKLGA19.bib},
 booktitle = {Advances in Neural Information Processing Systems 32: Annual Conference
on Neural Information Processing Systems 2019, NeurIPS 2019, December
8-14, 2019, Vancouver, BC, Canada},
 editor = {Hanna M. Wallach and
Hugo Larochelle and
Alina Beygelzimer and
Florence d'Alch{\'{e}}{-}Buc and
Emily B. Fox and
Roman Garnett},
 pages = {8024--8035},
 timestamp = {Thu, 21 Jan 2021 00:00:00 +0100},
 title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
 url = {https://proceedings.neurips.cc/paper/2019/hash/bdbca288fee7f92f2bfa9f7012727740-Abstract.html},
 year = {2019}
}

@misc{PyTorch_Lightning,
 abstract = {The lightweight PyTorch wrapper for high-performance AI research. Scale your models, not the boilerplate.},
 author = {William Falcon and The PyTorch Lightning team},
 doi = {10.5281/zenodo.3828935},
 keywords = {machine learning, deep learning, artificial intelligence},
 license = {Apache-2.0},
 repository = {https://github.com/Lightning-AI/lightning},
 title = {PyTorch Lightning},
 url = {https://www.pytorchlightning.ai},
 version = {1.4},
 year = {2019}
}

@article{scikit_learn,
 author = {Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal = {Journal of Machine Learning Research},
 pages = {2825--2830},
 title = {Scikit-learn: Machine Learning in {P}ython},
 volume = {12},
 year = {2011}
}
