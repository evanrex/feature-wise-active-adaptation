Loading rhel8/default-amp
  Loading requirement: dot rhel8/slurm singularity/current rhel8/global
    cuda/11.4 libpciaccess/0.16/gcc-9.4.0-6fonbj6
    libiconv/1.16/gcc-9.4.0-ahebbov libxml2/2.9.12/gcc-9.4.0-gnknt5e
    ncurses/6.2/gcc-9.4.0-aiirok7 hwloc/2.5.0/gcc-9.4.0-7sqomga
    libevent/2.1.12/gcc-9.4.0-hgny7cm numactl/2.0.14/gcc-9.4.0-52dwc6n
    cuda/11.4.0/gcc-9.4.0-3hnxhjt gdrcopy/2.2/gcc-9.4.0-e4igtfp
    knem/1.1.4/gcc-9.4.0-bpbxgva libnl/3.3.0/gcc-9.4.0-whwhrwb
    rdma-core/34.0/gcc-9.4.0-5eo5n2u ucx/1.11.1/gcc-9.4.0-lktqyl4
    openmpi/4.1.1/gcc-9.4.0-epagguv
Changed directory to /home/er647/projects/feature-wise-active-learning.

JobID: 42476582
======
Time: Sat Jan 20 17:45:29 GMT 2024
Running on master node: gpu-q-67
Current directory: /home/er647/projects/feature-wise-active-learning

Nodes allocated:
================
gpu-q-67

numtasks=4, numnodes=1, mpi_tasks_per_node=4 (OMP_NUM_THREADS=1)

Executing command:
==================
wandb agent evangeorgerex/fwal/put82sk9

wandb: Starting wandb agent üïµÔ∏è
2024-01-20 17:45:39,271 - wandb.wandb_agent - INFO - Running runs: []
2024-01-20 17:45:39,531 - wandb.wandb_agent - INFO - Agent received command: run
2024-01-20 17:45:39,532 - wandb.wandb_agent - INFO - Agent starting run with config:
	dataset: simple_trig_synth
	mask_type: sigmoid
	repeat_id: 0
	seed_model_init: 0
	seed_model_mask: 0
2024-01-20 17:45:39,537 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python /home/er647/projects/feature-wise-active-learning/src/run_experiment.py --model fwal --valid_percentage 0.25 --sparsity_type global --gamma 1 --sparsity_regularizer L1 --sparsity_regularizer_hyperparam 1 --test_time_interventions evaluate_test_time_interventions --tags ca003302 --notes "Evaluating random mask init. Gumbel and Softmax. All 5 datasets. x3 test splits x3 weight inits" --dataset=simple_trig_synth --mask_type=sigmoid --repeat_id=0 --seed_model_init=0 --seed_model_mask=0
2024-01-20 17:45:44,550 - wandb.wandb_agent - INFO - Running runs: ['u9nkhwoq']
wandb: Currently logged in as: evangeorgerex. Use `wandb login --relogin` to force relogin
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.16.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.1
wandb: Run data is saved locally in ./wandb/run-20240120_174557-u9nkhwoq
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run playful-sweep-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/evangeorgerex/fwal
wandb: üßπ View sweep at https://wandb.ai/evangeorgerex/fwal/sweeps/put82sk9
wandb: üöÄ View run at https://wandb.ai/evangeorgerex/fwal/runs/u9nkhwoq
wandb: WARNING Config item 'dataset' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'mask_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'repeat_id' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'seed_model_init' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'seed_model_mask' was locked by 'sweep' (ignored update).
[rank: 0] Seed set to 0
[rank: 0] Seed set to 42
Starting...

Inside training function

Loading data simple_trig_synth...
Train size: 6000

Valid size: 2000

Test size: 2000

Weights for the classification loss: [1. 1.]
Train/Valid/Test splits of sizes 6000, 2000, 2000
Num of features: 5
Training for max_epochs = 14
Traceback (most recent call last):
  File "/home/er647/projects/feature-wise-active-learning/src/run_experiment.py", line 750, in <module>
    run_experiment(args)
  File "/home/er647/projects/feature-wise-active-learning/src/run_experiment.py", line 244, in run_experiment
    trainer, checkpoint_callback = train_model(args, model, data_module, wandb_logger)
  File "/home/er647/projects/feature-wise-active-learning/src/run_experiment.py", line 319, in train_model
    trainer = pl.Trainer(
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 401, in __init__
    self._accelerator_connector = _AcceleratorConnector(
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py", line 158, in __init__
    self.cluster_environment: ClusterEnvironment = self._choose_and_init_cluster_environment()
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py", line 428, in _choose_and_init_cluster_environment
    return env_type()
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py", line 52, in __init__
    self._validate_srun_variables()
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py", line 208, in _validate_srun_variables
    raise RuntimeError(
RuntimeError: You set `--ntasks=4` in your SLURM bash script, but this variable is not supported. HINT: Use `--ntasks-per-node=4` instead.
2024-01-20 17:45:59,960 - wandb.wandb_agent - INFO - Cleaning up finished run: u9nkhwoq
wandb: üöÄ View run playful-sweep-1 at: https://wandb.ai/evangeorgerex/fwal/runs/u9nkhwoq
wandb: Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240120_174557-u9nkhwoq/logs
2024-01-20 17:46:05,514 - wandb.wandb_agent - INFO - Agent received command: run
2024-01-20 17:46:05,514 - wandb.wandb_agent - INFO - Agent starting run with config:
	dataset: simple_trig_synth
	mask_type: sigmoid
	repeat_id: 0
	seed_model_init: 0
	seed_model_mask: 1
2024-01-20 17:46:05,519 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python /home/er647/projects/feature-wise-active-learning/src/run_experiment.py --model fwal --valid_percentage 0.25 --sparsity_type global --gamma 1 --sparsity_regularizer L1 --sparsity_regularizer_hyperparam 1 --test_time_interventions evaluate_test_time_interventions --tags ca003302 --notes "Evaluating random mask init. Gumbel and Softmax. All 5 datasets. x3 test splits x3 weight inits" --dataset=simple_trig_synth --mask_type=sigmoid --repeat_id=0 --seed_model_init=0 --seed_model_mask=1
2024-01-20 17:46:10,530 - wandb.wandb_agent - INFO - Running runs: ['id43dc5y']
wandb: Currently logged in as: evangeorgerex. Use `wandb login --relogin` to force relogin
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.16.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.1
wandb: Run data is saved locally in ./wandb/run-20240120_174614-id43dc5y
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run olive-sweep-2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/evangeorgerex/fwal
wandb: üßπ View sweep at https://wandb.ai/evangeorgerex/fwal/sweeps/put82sk9
wandb: üöÄ View run at https://wandb.ai/evangeorgerex/fwal/runs/id43dc5y
wandb: WARNING Config item 'dataset' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'mask_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'repeat_id' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'seed_model_init' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'seed_model_mask' was locked by 'sweep' (ignored update).
[rank: 0] Seed set to 0
[rank: 0] Seed set to 42
Starting...

Inside training function

Loading data simple_trig_synth...
Train size: 6000

Valid size: 2000

Test size: 2000

Weights for the classification loss: [1. 1.]
Train/Valid/Test splits of sizes 6000, 2000, 2000
Num of features: 5
Training for max_epochs = 14
Traceback (most recent call last):
  File "/home/er647/projects/feature-wise-active-learning/src/run_experiment.py", line 750, in <module>
    run_experiment(args)
  File "/home/er647/projects/feature-wise-active-learning/src/run_experiment.py", line 244, in run_experiment
    trainer, checkpoint_callback = train_model(args, model, data_module, wandb_logger)
  File "/home/er647/projects/feature-wise-active-learning/src/run_experiment.py", line 319, in train_model
    trainer = pl.Trainer(
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 401, in __init__
    self._accelerator_connector = _AcceleratorConnector(
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py", line 158, in __init__
    self.cluster_environment: ClusterEnvironment = self._choose_and_init_cluster_environment()
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py", line 428, in _choose_and_init_cluster_environment
    return env_type()
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py", line 52, in __init__
    self._validate_srun_variables()
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py", line 208, in _validate_srun_variables
    raise RuntimeError(
RuntimeError: You set `--ntasks=4` in your SLURM bash script, but this variable is not supported. HINT: Use `--ntasks-per-node=4` instead.
Traceback (most recent call last):
  File "/home/er647/projects/feature-wise-active-learning/src/run_experiment.py", line 750, in <module>
    run_experiment(args)
  File "/home/er647/projects/feature-wise-active-learning/src/run_experiment.py", line 244, in run_experiment
    trainer, checkpoint_callback = train_model(args, model, data_module, wandb_logger)
  File "/home/er647/projects/feature-wise-active-learning/src/run_experiment.py", line 319, in train_model
    trainer = pl.Trainer(
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 401, in __init__
    self._accelerator_connector = _AcceleratorConnector(
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py", line 158, in __init__
    self.cluster_environment: ClusterEnvironment = self._choose_and_init_cluster_environment()
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py", line 428, in _choose_and_init_cluster_environment
    return env_type()
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py", line 52, in __init__
    self._validate_srun_variables()
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py", line 208, in _validate_srun_variables
    raise RuntimeError(
RuntimeError: You set `--ntasks=4` in your SLURM bash script, but this variable is not supported. HINT: Use `--ntasks-per-node=4` instead.
wandb: - 0.000 MB of 0.000 MB uploadedwandb: \ 0.000 MB of 0.000 MB uploadedwandb: | 0.000 MB of 0.009 MB uploadedwandb: / 0.009 MB of 0.009 MB uploadedwandb: üöÄ View run olive-sweep-2 at: https://wandb.ai/evangeorgerex/fwal/runs/id43dc5y
wandb: Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240120_174614-id43dc5y/logs
2024-01-20 17:46:25,949 - wandb.wandb_agent - INFO - Cleaning up finished run: id43dc5y
2024-01-20 17:46:26,248 - wandb.wandb_agent - INFO - Agent received command: run
2024-01-20 17:46:26,248 - wandb.wandb_agent - INFO - Agent starting run with config:
	dataset: simple_trig_synth
	mask_type: sigmoid
	repeat_id: 0
	seed_model_init: 0
	seed_model_mask: 2
2024-01-20 17:46:26,252 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python /home/er647/projects/feature-wise-active-learning/src/run_experiment.py --model fwal --valid_percentage 0.25 --sparsity_type global --gamma 1 --sparsity_regularizer L1 --sparsity_regularizer_hyperparam 1 --test_time_interventions evaluate_test_time_interventions --tags ca003302 --notes "Evaluating random mask init. Gumbel and Softmax. All 5 datasets. x3 test splits x3 weight inits" --dataset=simple_trig_synth --mask_type=sigmoid --repeat_id=0 --seed_model_init=0 --seed_model_mask=2
2024-01-20 17:46:31,263 - wandb.wandb_agent - INFO - Running runs: ['d0aa664i']
wandb: Currently logged in as: evangeorgerex. Use `wandb login --relogin` to force relogin
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.16.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.1
wandb: Run data is saved locally in ./wandb/run-20240120_174633-d0aa664i
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run robust-sweep-3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/evangeorgerex/fwal
wandb: üßπ View sweep at https://wandb.ai/evangeorgerex/fwal/sweeps/put82sk9
wandb: üöÄ View run at https://wandb.ai/evangeorgerex/fwal/runs/d0aa664i
wandb: WARNING Config item 'dataset' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'mask_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'repeat_id' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'seed_model_init' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'seed_model_mask' was locked by 'sweep' (ignored update).
[rank: 0] Seed set to 0
[rank: 0] Seed set to 42
Starting...

Inside training function

Loading data simple_trig_synth...
Train size: 6000

Valid size: 2000

Test size: 2000

Weights for the classification loss: [1. 1.]
Train/Valid/Test splits of sizes 6000, 2000, 2000
Num of features: 5
Training for max_epochs = 14
Traceback (most recent call last):
  File "/home/er647/projects/feature-wise-active-learning/src/run_experiment.py", line 750, in <module>
    run_experiment(args)
  File "/home/er647/projects/feature-wise-active-learning/src/run_experiment.py", line 244, in run_experiment
    trainer, checkpoint_callback = train_model(args, model, data_module, wandb_logger)
  File "/home/er647/projects/feature-wise-active-learning/src/run_experiment.py", line 319, in train_model
    trainer = pl.Trainer(
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 401, in __init__
    self._accelerator_connector = _AcceleratorConnector(
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py", line 158, in __init__
    self.cluster_environment: ClusterEnvironment = self._choose_and_init_cluster_environment()
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py", line 428, in _choose_and_init_cluster_environment
    return env_type()
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py", line 52, in __init__
    self._validate_srun_variables()
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py", line 208, in _validate_srun_variables
    raise RuntimeError(
RuntimeError: You set `--ntasks=4` in your SLURM bash script, but this variable is not supported. HINT: Use `--ntasks-per-node=4` instead.
Traceback (most recent call last):
  File "/home/er647/projects/feature-wise-active-learning/src/run_experiment.py", line 750, in <module>
    run_experiment(args)
  File "/home/er647/projects/feature-wise-active-learning/src/run_experiment.py", line 244, in run_experiment
    trainer, checkpoint_callback = train_model(args, model, data_module, wandb_logger)
  File "/home/er647/projects/feature-wise-active-learning/src/run_experiment.py", line 319, in train_model
    trainer = pl.Trainer(
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 401, in __init__
    self._accelerator_connector = _AcceleratorConnector(
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py", line 158, in __init__
    self.cluster_environment: ClusterEnvironment = self._choose_and_init_cluster_environment()
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py", line 428, in _choose_and_init_cluster_environment
    return env_type()
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py", line 52, in __init__
    self._validate_srun_variables()
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py", line 208, in _validate_srun_variables
    raise RuntimeError(
RuntimeError: You set `--ntasks=4` in your SLURM bash script, but this variable is not supported. HINT: Use `--ntasks-per-node=4` instead.
wandb: üöÄ View run robust-sweep-3 at: https://wandb.ai/evangeorgerex/fwal/runs/d0aa664i
wandb: Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240120_174633-d0aa664i/logs
2024-01-20 17:46:41,532 - wandb.wandb_agent - INFO - Cleaning up finished run: d0aa664i
2024-01-20 17:46:41,821 - wandb.wandb_agent - INFO - Agent received command: run
2024-01-20 17:46:41,821 - wandb.wandb_agent - INFO - Agent starting run with config:
	dataset: simple_trig_synth
	mask_type: sigmoid
	repeat_id: 0
	seed_model_init: 0
	seed_model_mask: 3
2024-01-20 17:46:41,826 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python /home/er647/projects/feature-wise-active-learning/src/run_experiment.py --model fwal --valid_percentage 0.25 --sparsity_type global --gamma 1 --sparsity_regularizer L1 --sparsity_regularizer_hyperparam 1 --test_time_interventions evaluate_test_time_interventions --tags ca003302 --notes "Evaluating random mask init. Gumbel and Softmax. All 5 datasets. x3 test splits x3 weight inits" --dataset=simple_trig_synth --mask_type=sigmoid --repeat_id=0 --seed_model_init=0 --seed_model_mask=3
2024-01-20 17:46:46,837 - wandb.wandb_agent - INFO - Running runs: ['qcivq0b2']
wandb: Currently logged in as: evangeorgerex. Use `wandb login --relogin` to force relogin
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.16.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.1
wandb: Run data is saved locally in ./wandb/run-20240120_174648-qcivq0b2
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run bumbling-sweep-4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/evangeorgerex/fwal
wandb: üßπ View sweep at https://wandb.ai/evangeorgerex/fwal/sweeps/put82sk9
wandb: üöÄ View run at https://wandb.ai/evangeorgerex/fwal/runs/qcivq0b2
wandb: WARNING Config item 'dataset' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'mask_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'repeat_id' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'seed_model_init' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'seed_model_mask' was locked by 'sweep' (ignored update).
[rank: 0] Seed set to 0
[rank: 0] Seed set to 42
Starting...

Inside training function

Loading data simple_trig_synth...
Train size: 6000

Valid size: 2000

Test size: 2000

Weights for the classification loss: [1. 1.]
Train/Valid/Test splits of sizes 6000, 2000, 2000
Num of features: 5
Training for max_epochs = 14
Traceback (most recent call last):
  File "/home/er647/projects/feature-wise-active-learning/src/run_experiment.py", line 750, in <module>
    run_experiment(args)
  File "/home/er647/projects/feature-wise-active-learning/src/run_experiment.py", line 244, in run_experiment
    trainer, checkpoint_callback = train_model(args, model, data_module, wandb_logger)
  File "/home/er647/projects/feature-wise-active-learning/src/run_experiment.py", line 319, in train_model
    trainer = pl.Trainer(
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 401, in __init__
    self._accelerator_connector = _AcceleratorConnector(
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py", line 158, in __init__
    self.cluster_environment: ClusterEnvironment = self._choose_and_init_cluster_environment()
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py", line 428, in _choose_and_init_cluster_environment
    return env_type()
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py", line 52, in __init__
    self._validate_srun_variables()
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py", line 208, in _validate_srun_variables
    raise RuntimeError(
RuntimeError: You set `--ntasks=4` in your SLURM bash script, but this variable is not supported. HINT: Use `--ntasks-per-node=4` instead.
Traceback (most recent call last):
  File "/home/er647/projects/feature-wise-active-learning/src/run_experiment.py", line 750, in <module>
    run_experiment(args)
  File "/home/er647/projects/feature-wise-active-learning/src/run_experiment.py", line 244, in run_experiment
    trainer, checkpoint_callback = train_model(args, model, data_module, wandb_logger)
  File "/home/er647/projects/feature-wise-active-learning/src/run_experiment.py", line 319, in train_model
    trainer = pl.Trainer(
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 401, in __init__
    self._accelerator_connector = _AcceleratorConnector(
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py", line 158, in __init__
    self.cluster_environment: ClusterEnvironment = self._choose_and_init_cluster_environment()
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py", line 428, in _choose_and_init_cluster_environment
    return env_type()
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py", line 52, in __init__
    self._validate_srun_variables()
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py", line 208, in _validate_srun_variables
    raise RuntimeError(
RuntimeError: You set `--ntasks=4` in your SLURM bash script, but this variable is not supported. HINT: Use `--ntasks-per-node=4` instead.
wandb: üöÄ View run bumbling-sweep-4 at: https://wandb.ai/evangeorgerex/fwal/runs/qcivq0b2
wandb: Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240120_174648-qcivq0b2/logs
2024-01-20 17:46:57,102 - wandb.wandb_agent - INFO - Cleaning up finished run: qcivq0b2
2024-01-20 17:46:57,495 - wandb.wandb_agent - INFO - Agent received command: run
2024-01-20 17:46:57,495 - wandb.wandb_agent - INFO - Agent starting run with config:
	dataset: simple_trig_synth
	mask_type: sigmoid
	repeat_id: 0
	seed_model_init: 0
	seed_model_mask: 4
2024-01-20 17:46:57,500 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python /home/er647/projects/feature-wise-active-learning/src/run_experiment.py --model fwal --valid_percentage 0.25 --sparsity_type global --gamma 1 --sparsity_regularizer L1 --sparsity_regularizer_hyperparam 1 --test_time_interventions evaluate_test_time_interventions --tags ca003302 --notes "Evaluating random mask init. Gumbel and Softmax. All 5 datasets. x3 test splits x3 weight inits" --dataset=simple_trig_synth --mask_type=sigmoid --repeat_id=0 --seed_model_init=0 --seed_model_mask=4
2024-01-20 17:47:02,511 - wandb.wandb_agent - INFO - Running runs: ['o9otsh5n']
wandb: Currently logged in as: evangeorgerex. Use `wandb login --relogin` to force relogin
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.16.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.1
wandb: Run data is saved locally in ./wandb/run-20240120_174703-o9otsh5n
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run peachy-sweep-5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/evangeorgerex/fwal
wandb: üßπ View sweep at https://wandb.ai/evangeorgerex/fwal/sweeps/put82sk9
wandb: üöÄ View run at https://wandb.ai/evangeorgerex/fwal/runs/o9otsh5n
wandb: WARNING Config item 'dataset' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'mask_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'repeat_id' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'seed_model_init' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'seed_model_mask' was locked by 'sweep' (ignored update).
[rank: 0] Seed set to 0
[rank: 0] Seed set to 42
Starting...

Inside training function

Loading data simple_trig_synth...
Train size: 6000

Valid size: 2000

Test size: 2000

Weights for the classification loss: [1. 1.]
Train/Valid/Test splits of sizes 6000, 2000, 2000
Num of features: 5
Training for max_epochs = 14
Traceback (most recent call last):
  File "/home/er647/projects/feature-wise-active-learning/src/run_experiment.py", line 750, in <module>
    run_experiment(args)
  File "/home/er647/projects/feature-wise-active-learning/src/run_experiment.py", line 244, in run_experiment
    trainer, checkpoint_callback = train_model(args, model, data_module, wandb_logger)
  File "/home/er647/projects/feature-wise-active-learning/src/run_experiment.py", line 319, in train_model
    trainer = pl.Trainer(
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 401, in __init__
    self._accelerator_connector = _AcceleratorConnector(
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py", line 158, in __init__
    self.cluster_environment: ClusterEnvironment = self._choose_and_init_cluster_environment()
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py", line 428, in _choose_and_init_cluster_environment
    return env_type()
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py", line 52, in __init__
    self._validate_srun_variables()
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py", line 208, in _validate_srun_variables
    raise RuntimeError(
RuntimeError: You set `--ntasks=4` in your SLURM bash script, but this variable is not supported. HINT: Use `--ntasks-per-node=4` instead.
Traceback (most recent call last):
  File "/home/er647/projects/feature-wise-active-learning/src/run_experiment.py", line 750, in <module>
    run_experiment(args)
  File "/home/er647/projects/feature-wise-active-learning/src/run_experiment.py", line 244, in run_experiment
    trainer, checkpoint_callback = train_model(args, model, data_module, wandb_logger)
  File "/home/er647/projects/feature-wise-active-learning/src/run_experiment.py", line 319, in train_model
    trainer = pl.Trainer(
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 401, in __init__
    self._accelerator_connector = _AcceleratorConnector(
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py", line 158, in __init__
    self.cluster_environment: ClusterEnvironment = self._choose_and_init_cluster_environment()
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py", line 428, in _choose_and_init_cluster_environment
    return env_type()
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py", line 52, in __init__
    self._validate_srun_variables()
  File "/home/er647/anaconda3/envs/fwal/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py", line 208, in _validate_srun_variables
    raise RuntimeError(
RuntimeError: You set `--ntasks=4` in your SLURM bash script, but this variable is not supported. HINT: Use `--ntasks-per-node=4` instead.
wandb: - 0.000 MB of 0.000 MB uploadedwandb: \ 0.000 MB of 0.009 MB uploadedwandb: | 0.009 MB of 0.009 MB uploadedwandb: üöÄ View run peachy-sweep-5 at: https://wandb.ai/evangeorgerex/fwal/runs/o9otsh5n
wandb: Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240120_174703-o9otsh5n/logs
2024-01-20 17:47:12,779 - wandb.wandb_agent - ERROR - Detected 5 failed runs in a row, shutting down.
2024-01-20 17:47:12,780 - wandb.wandb_agent - INFO - To change this value set WANDB_AGENT_MAX_INITIAL_FAILURES=val
wandb: Terminating and syncing runs. Press ctrl-c to kill.
