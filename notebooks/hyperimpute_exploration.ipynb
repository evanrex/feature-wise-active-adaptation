{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from math import sqrt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from hyperimpute.plugins.utils.metrics import RMSE\n",
    "from hyperimpute.plugins.utils.simulate import simulate_nan\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperimpute.plugins.imputers import Imputers, ImputerPlugin\n",
    "\n",
    "imputers = Imputers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r\"/home/er647/data/fwal-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ASU_dataset(data_dir, dataset):\n",
    "\tmat = scipy.io.loadmat(os.path.join(data_dir, \"ASU_datasets\", f\"{dataset}.mat\"))\n",
    "\tX = mat['X']\n",
    "\ty = np.squeeze(mat['Y'])\n",
    "\tX = X.astype(np.float64)\n",
    "\ty = y.astype(np.int64)\n",
    "\n",
    "\tif y.min() == 1 and y.max() == len(set(y)):\n",
    "\t\ty -= 1\n",
    "\t\n",
    "\tif y.min() == -1 and y.max() == 1 and len(set(y)) == 2:\n",
    "\t\ty = (y + 1) // 2\n",
    "\n",
    "\treturn X, y\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_ASU_dataset(data_dir, 'madelon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (2600, 500))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X), X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (2080, 500))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train), X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_MCAR_datasets(X_valid, X_test, fraction = 0.1, seed = 0, replace_val = 0, include_train = False):\n",
    "    \"\"\"\n",
    "    Missing data mechanism\n",
    "    - fraction (float): percentage of missing values\n",
    "    - seed (int): seed for reproducibility\n",
    "    - replace_val: 0 or np.nan for example\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    missing_mask_valid = np.random.choice([0, 1], size=X_valid.shape, p=[1-fraction, fraction])\n",
    "    missing_mask_test = np.random.choice([0, 1], size=X_test.shape, p=[1-fraction, fraction])\n",
    "\n",
    "\n",
    "    X_valid_missing = X_valid.copy()\n",
    "    X_valid_missing[missing_mask_valid==1] = replace_val\n",
    "\n",
    "    X_test_missing = X_test.copy()\n",
    "    X_test_missing[missing_mask_test==1] = replace_val\n",
    "    return X_valid_missing, X_test_missing, missing_mask_valid, missing_mask_test\n",
    "X_valid_missing, X_test_missing, missing_mask_valid, missing_mask_test = gen_MCAR_datasets(X_train, X_test, replace_val=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['median',\n",
       " 'most_frequent',\n",
       " 'sinkhorn',\n",
       " 'missforest',\n",
       " 'ice',\n",
       " 'miracle',\n",
       " 'mean',\n",
       " 'sklearn_missforest',\n",
       " 'nop',\n",
       " 'sklearn_ice',\n",
       " 'EM',\n",
       " 'miwae',\n",
       " 'softimpute',\n",
       " 'mice',\n",
       " 'gain',\n",
       " 'hyperimpute']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputers.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miwae  | # NaNs in test set:  25963 | # NaNs in imputed set:  0 | time (seconds):  45.5957 | MSE:  214146.89860067665\n",
      "mean  | # NaNs in test set:  25963 | # NaNs in imputed set:  0 | time (seconds):  0.0585 | MSE:  898.521319990077\n",
      "sklearn_missforest  | # NaNs in test set:  25963 | # NaNs in imputed set:  0 | time (seconds):  118.7317 | MSE:  699.7983433008646\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "benchmarks = [\n",
    "    'miwae',\n",
    "    # 'softimpute',\n",
    "    'mean',\n",
    "    # 'miracle',\n",
    "    # 'sinkhorn',\n",
    "    'sklearn_missforest',\n",
    "    # 'most_frequent',\n",
    "    # 'EM', # too slow\n",
    "    # 'nop',\n",
    "    # 'hyperimpute', # too slow\n",
    "    # 'gain',\n",
    "    # 'median',\n",
    "    # 'ice',\n",
    "    # 'mice', # too slow\n",
    "    # 'sklearn_ice',\n",
    "    # 'missforest' # too slow\n",
    "]\n",
    "\n",
    "# for benchmark in ['mean']:\n",
    "for benchmark in benchmarks:\n",
    "    start = time.time()\n",
    "    imputer = imputers.get(benchmark, random_state=42)\n",
    "    fitted_imputer = imputer.fit(X_train)\n",
    "    X_test_imputed = fitted_imputer.transform(X_test_missing).to_numpy()\n",
    "    missing_mask = np.isnan(X_test_missing)  # Creating the mask where X_test_missing is NaN\n",
    "    mse = mean_squared_error(X_test[missing_mask], X_test_imputed[missing_mask])  # Calculating MSE only for missing values\n",
    "    print(benchmark,' | # NaNs in test set: ', np.isnan(X_test_missing).sum(), '| # NaNs in imputed set: ',np.isnan(X_test_imputed).sum(),'| time (seconds): ', round(time.time() - start, 4), '| MSE: ',mse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = imputers.get('ice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_imputer = imputer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_imputed = fitted_imputer.transform(X_test_missing).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fwal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
