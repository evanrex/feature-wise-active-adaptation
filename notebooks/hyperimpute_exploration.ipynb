{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from math import sqrt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from hyperimpute.plugins.utils.metrics import RMSE\n",
    "from hyperimpute.plugins.utils.simulate import simulate_nan\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperimpute.plugins.imputers import Imputers, ImputerPlugin\n",
    "\n",
    "imputers = Imputers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r\"/home/er647/data/fwal-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ASU_dataset(data_dir, dataset):\n",
    "\tmat = scipy.io.loadmat(os.path.join(data_dir, \"ASU_datasets\", f\"{dataset}.mat\"))\n",
    "\tX = mat['X']\n",
    "\ty = np.squeeze(mat['Y'])\n",
    "\tX = X.astype(np.float64)\n",
    "\ty = y.astype(np.int64)\n",
    "\n",
    "\tif y.min() == 1 and y.max() == len(set(y)):\n",
    "\t\ty -= 1\n",
    "\t\n",
    "\tif y.min() == -1 and y.max() == 1 and len(set(y)) == 2:\n",
    "\t\ty = (y + 1) // 2\n",
    "\n",
    "\treturn X, y\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_finance(data_dir):\n",
    "\tdata = pd.read_csv(f'{data_dir}/Finance/finance.csv')\n",
    "\tX = data.drop(columns=['Class'])\n",
    "\tY = data['Class']\n",
    "\t# convert dtype of Y to int\n",
    "\tY = Y.astype(int)\n",
    "\treturn X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = load_ASU_dataset(data_dir, 'madelon')\n",
    "X, y = load_finance(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type(X)==pd.DataFrame:\n",
    "    X = X.to_numpy()\n",
    "if type(y)==pd.Series or type(y)==pd.DataFrame:\n",
    "    y = y.to_numpy()\n",
    "\n",
    "assert type(X)==np.ndarray\n",
    "assert type(y)==np.ndarray\n",
    "\n",
    "# Split validation set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train).astype(np.float32)\n",
    "X_test = scaler.transform(X_test).astype(np.float32)\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (2664, 154))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X), X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (2131, 154))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train), X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_MCAR_datasets(X_valid, X_test, fraction = 0.2, seed = 0, replace_val = 0, include_train = False):\n",
    "    \"\"\"\n",
    "    Missing data mechanism\n",
    "    - fraction (float): percentage of missing values\n",
    "    - seed (int): seed for reproducibility\n",
    "    - replace_val: 0 or np.nan for example\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    missing_mask_valid = np.random.choice([0, 1], size=X_valid.shape, p=[1-fraction, fraction])\n",
    "    missing_mask_test = np.random.choice([0, 1], size=X_test.shape, p=[1-fraction, fraction])\n",
    "\n",
    "\n",
    "    X_valid_missing = X_valid.copy()\n",
    "    X_valid_missing[missing_mask_valid==1] = replace_val\n",
    "\n",
    "    X_test_missing = X_test.copy()\n",
    "    X_test_missing[missing_mask_test==1] = replace_val\n",
    "    return X_valid_missing, X_test_missing, missing_mask_valid, missing_mask_test\n",
    "X_valid_missing, X_test_missing, missing_mask_valid, missing_mask_test = gen_MCAR_datasets(X_train, X_test, replace_val=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(np.isinf(X_test_missing) & ~np.isnan(X_test_missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['median',\n",
       " 'ice',\n",
       " 'mice',\n",
       " 'hyperimpute',\n",
       " 'miwae',\n",
       " 'most_frequent',\n",
       " 'softimpute',\n",
       " 'sklearn_missforest',\n",
       " 'EM',\n",
       " 'mean',\n",
       " 'nop',\n",
       " 'sinkhorn',\n",
       " 'missforest',\n",
       " 'gain',\n",
       " 'miracle',\n",
       " 'sklearn_ice']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputers.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ice  | # NaNs in test set:  16362 | # NaNs in imputed set:  0 | fit time:  0.0937 | transform time (seconds):  130.6002 | MSE:  39.49619\n"
     ]
    }
   ],
   "source": [
    "benchmarks = [\n",
    "    # 'miwae', # too computationally expensive\n",
    "    # 'softimpute',\n",
    "    # 'mean',\n",
    "    # 'miracle', # too slow\n",
    "    # 'sinkhorn',\n",
    "    # 'sklearn_missforest',\n",
    "    # 'most_frequent',\n",
    "    # 'EM', # too slow\n",
    "    # 'nop',\n",
    "    # 'hyperimpute', # too slow\n",
    "    # 'gain',\n",
    "    # 'median',\n",
    "    'ice', # too slow\n",
    "    # 'mice', # too slow\n",
    "    # 'sklearn_ice',\n",
    "    # 'missforest' # too slow\n",
    "]\n",
    "\n",
    "# for benchmark in ['sklearn_ice', 'sinkhorn', 'gain', 'softimpute']:\n",
    "for benchmark in benchmarks:\n",
    "    start = time.time()\n",
    "    imputer = imputers.get(benchmark, random_state=42)\n",
    "    fitted_imputer = imputer.fit(X_train)\n",
    "    fit_time = round(time.time() - start, 4)\n",
    "    start = time.time()\n",
    "    X_test_imputed = fitted_imputer.transform(X_test_missing).to_numpy()\n",
    "    missing_mask = np.isnan(X_test_missing)  # Creating the mask where X_test_missing is NaN\n",
    "    mse = mean_squared_error(X_test[missing_mask], X_test_imputed[missing_mask])  # Calculating MSE only for missing values\n",
    "    print(benchmark,' | # NaNs in test set: ', np.isnan(X_test_missing).sum(), '| # NaNs in imputed set: ',np.isnan(X_test_imputed).sum(),'| fit time: ',fit_time, '| transform time (seconds): ', round(time.time() - start, 4), '| MSE: ',mse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_imputed = fitted_imputer.transform(X_test_missing).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = imputers.get('ice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_imputer = imputer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_imputed = fitted_imputer.transform(X_test_missing).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fwal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
