{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source\n",
    "\n",
    "https://docs.scvi-tools.org/en/stable/api/reference/scvi.data.purified_pbmc_dataset.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scvi\n",
    "import numpy as np\n",
    "save_path = \"/home/er647/data/fwal-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m File \u001b[35m/home/er647/data/fwal-data/\u001b[0m\u001b[95mPurifiedPBMCDataset.h5ad\u001b[0m already downloaded                               \n"
     ]
    }
   ],
   "source": [
    "adata = scvi.data.purified_pbmc_dataset(save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"S100A4\" in adata.var.index.to_list() and \"IL32\" in adata.var.index.to_list() and \"DUSP1\"  in adata.var.index.to_list() # (also known as MKP-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = adata[adata.obs['cell_types'].isin(['naive_t', 'regulatory_t'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = adata.X.toarray()\n",
    "y = np.array(adata.obs['cell_types'].map({'naive_t': 0, 'regulatory_t': 1}).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (20742,), dtype('int64'))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y), y.shape, y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (20742, 21932), dtype('float32'))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X), X.shape, X.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(y).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_types</th>\n",
       "      <th>barcodes</th>\n",
       "      <th>labels</th>\n",
       "      <th>batch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11213</th>\n",
       "      <td>regulatory_t</td>\n",
       "      <td>AAACATACAAAACG-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11214</th>\n",
       "      <td>regulatory_t</td>\n",
       "      <td>AAACATACACGACT-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11215</th>\n",
       "      <td>regulatory_t</td>\n",
       "      <td>AAACATACACTTTC-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11216</th>\n",
       "      <td>regulatory_t</td>\n",
       "      <td>AAACATACCCTCGT-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11217</th>\n",
       "      <td>regulatory_t</td>\n",
       "      <td>AAACATACGCTTAG-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cell_types          barcodes  labels  batch\n",
       "11213  regulatory_t  AAACATACAAAACG-1       1      1\n",
       "11214  regulatory_t  AAACATACACGACT-1       1      1\n",
       "11215  regulatory_t  AAACATACACTTTC-1       1      1\n",
       "11216  regulatory_t  AAACATACCCTCGT-1       1      1\n",
       "11217  regulatory_t  AAACATACGCTTAG-1       1      1"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values before the hyphen: 10838\n",
      "Unique values after the hyphen: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert index to list of strings and split by hyphen\n",
    "split_index = [x.split('-') for x in df.index]\n",
    "\n",
    "# Separate into two lists: before and after the hyphen\n",
    "before_hyphen = [x[0] for x in split_index]\n",
    "after_hyphen = [x[1] for x in split_index]\n",
    "\n",
    "# Find unique values and count them\n",
    "unique_before = len(set(before_hyphen))\n",
    "unique_after = len(set(after_hyphen))\n",
    "\n",
    "print(f'Unique values before the hyphen: {unique_before}')\n",
    "print(f'Unique values after the hyphen: {unique_after}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10849, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_lengths = [len(x) for x in before_hyphen]\n",
    "\n",
    "unique_index_lengths = len(set(index_lengths))\n",
    "len(index_lengths), unique_index_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10849"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(adata.obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on AnnData in module anndata._core.anndata object:\n",
      "\n",
      "class AnnData(builtins.object)\n",
      " |  AnnData(X: 'np.ndarray | sparse.spmatrix | pd.DataFrame | None' = None, obs: 'pd.DataFrame | Mapping[str, Iterable[Any]] | None' = None, var: 'pd.DataFrame | Mapping[str, Iterable[Any]] | None' = None, uns: 'Mapping[str, Any] | None' = None, obsm: 'np.ndarray | Mapping[str, Sequence[Any]] | None' = None, varm: 'np.ndarray | Mapping[str, Sequence[Any]] | None' = None, layers: 'Mapping[str, np.ndarray | sparse.spmatrix] | None' = None, raw: 'Mapping[str, Any] | None' = None, dtype: 'np.dtype | type | str | None' = None, shape: 'tuple[int, int] | None' = None, filename: 'PathLike | None' = None, filemode: \"Literal['r', 'r+'] | None\" = None, asview: 'bool' = False, *, obsp: 'np.ndarray | Mapping[str, Sequence[Any]] | None' = None, varp: 'np.ndarray | Mapping[str, Sequence[Any]] | None' = None, oidx: 'Index1D' = None, vidx: 'Index1D' = None)\n",
      " |  \n",
      " |  An annotated data matrix.\n",
      " |  \n",
      " |  .. figure:: ../_static/img/anndata_schema.svg\n",
      " |     :width: 260px\n",
      " |     :align: right\n",
      " |     :class: dark-light\n",
      " |  \n",
      " |  :class:`~anndata.AnnData` stores a data matrix :attr:`X` together with annotations\n",
      " |  of observations :attr:`obs` (:attr:`obsm`, :attr:`obsp`),\n",
      " |  variables :attr:`var` (:attr:`varm`, :attr:`varp`),\n",
      " |  and unstructured annotations :attr:`uns`.\n",
      " |  \n",
      " |  An :class:`~anndata.AnnData` object `adata` can be sliced like a\n",
      " |  :class:`~pandas.DataFrame`,\n",
      " |  for instance `adata_subset = adata[:, list_of_variable_names]`.\n",
      " |  :class:`~anndata.AnnData`’s basic structure is similar to R’s ExpressionSet\n",
      " |  [Huber15]_. If setting an `.h5ad`-formatted HDF5 backing file `.filename`,\n",
      " |  data remains on the disk but is automatically loaded into memory if needed.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  X\n",
      " |      A #observations × #variables data matrix. A view of the data is used if the\n",
      " |      data type matches, otherwise, a copy is made.\n",
      " |  obs\n",
      " |      Key-indexed one-dimensional observations annotation of length #observations.\n",
      " |  var\n",
      " |      Key-indexed one-dimensional variables annotation of length #variables.\n",
      " |  uns\n",
      " |      Key-indexed unstructured annotation.\n",
      " |  obsm\n",
      " |      Key-indexed multi-dimensional observations annotation of length #observations.\n",
      " |      If passing a :class:`~numpy.ndarray`, it needs to have a structured datatype.\n",
      " |  varm\n",
      " |      Key-indexed multi-dimensional variables annotation of length #variables.\n",
      " |      If passing a :class:`~numpy.ndarray`, it needs to have a structured datatype.\n",
      " |  layers\n",
      " |      Key-indexed multi-dimensional arrays aligned to dimensions of `X`.\n",
      " |  shape\n",
      " |      Shape tuple (#observations, #variables). Can only be provided if `X` is `None`.\n",
      " |  filename\n",
      " |      Name of backing file. See :class:`h5py.File`.\n",
      " |  filemode\n",
      " |      Open mode of backing file. See :class:`h5py.File`.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  read_h5ad\n",
      " |  read_csv\n",
      " |  read_excel\n",
      " |  read_hdf\n",
      " |  read_loom\n",
      " |  read_zarr\n",
      " |  read_mtx\n",
      " |  read_text\n",
      " |  read_umi_tools\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  :class:`~anndata.AnnData` stores observations (samples) of variables/features\n",
      " |  in the rows of a matrix.\n",
      " |  This is the convention of the modern classics of statistics [Hastie09]_\n",
      " |  and machine learning [Murphy12]_,\n",
      " |  the convention of dataframes both in R and Python and the established statistics\n",
      " |  and machine learning packages in Python (statsmodels_, scikit-learn_).\n",
      " |  \n",
      " |  Single dimensional annotations of the observation and variables are stored\n",
      " |  in the :attr:`obs` and :attr:`var` attributes as :class:`~pandas.DataFrame`\\ s.\n",
      " |  This is intended for metrics calculated over their axes.\n",
      " |  Multi-dimensional annotations are stored in :attr:`obsm` and :attr:`varm`,\n",
      " |  which are aligned to the objects observation and variable dimensions respectively.\n",
      " |  Square matrices representing graphs are stored in :attr:`obsp` and :attr:`varp`,\n",
      " |  with both of their own dimensions aligned to their associated axis.\n",
      " |  Additional measurements across both observations and variables are stored in\n",
      " |  :attr:`layers`.\n",
      " |  \n",
      " |  Indexing into an AnnData object can be performed by relative position\n",
      " |  with numeric indices (like pandas’ :meth:`~pandas.DataFrame.iloc`),\n",
      " |  or by labels (like :meth:`~pandas.DataFrame.loc`).\n",
      " |  To avoid ambiguity with numeric indexing into observations or variables,\n",
      " |  indexes of the AnnData object are converted to strings by the constructor.\n",
      " |  \n",
      " |  Subsetting an AnnData object by indexing into it will also subset its elements\n",
      " |  according to the dimensions they were aligned to.\n",
      " |  This means an operation like `adata[list_of_obs, :]` will also subset :attr:`obs`,\n",
      " |  :attr:`obsm`, and :attr:`layers`.\n",
      " |  \n",
      " |  Subsetting an AnnData object returns a view into the original object,\n",
      " |  meaning very little additional memory is used upon subsetting.\n",
      " |  This is achieved lazily, meaning that the constituent arrays are subset on access.\n",
      " |  Copying a view causes an equivalent “real” AnnData object to be generated.\n",
      " |  Attempting to modify a view (at any attribute except X) is handled\n",
      " |  in a copy-on-modify manner, meaning the object is initialized in place.\n",
      " |  Here’s an example::\n",
      " |  \n",
      " |      batch1 = adata[adata.obs[\"batch\"] == \"batch1\", :]\n",
      " |      batch1.obs[\"value\"] = 0  # This makes batch1 a “real” AnnData object\n",
      " |  \n",
      " |  At the end of this snippet: `adata` was not modified,\n",
      " |  and `batch1` is its own AnnData object with its own data.\n",
      " |  \n",
      " |  Similar to Bioconductor’s `ExpressionSet` and :mod:`scipy.sparse` matrices,\n",
      " |  subsetting an AnnData object retains the dimensionality of its constituent arrays.\n",
      " |  Therefore, unlike with the classes exposed by :mod:`pandas`, :mod:`numpy`,\n",
      " |  and `xarray`, there is no concept of a one dimensional AnnData object.\n",
      " |  AnnDatas always have two inherent dimensions, :attr:`obs` and :attr:`var`.\n",
      " |  Additionally, maintaining the dimensionality of the AnnData object allows for\n",
      " |  consistent handling of :mod:`scipy.sparse` matrices and :mod:`numpy` arrays.\n",
      " |  \n",
      " |  .. _statsmodels: http://www.statsmodels.org/stable/index.html\n",
      " |  .. _scikit-learn: http://scikit-learn.org/\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __contains__(self, key: 'Any')\n",
      " |  \n",
      " |  __delitem__(self, index: 'Index')\n",
      " |      # TODO: this is not quite complete...\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Equality testing\n",
      " |  \n",
      " |  __getitem__(self, index: 'Index') -> 'AnnData'\n",
      " |      Returns a sliced view of the object.\n",
      " |  \n",
      " |  __init__(self, X: 'np.ndarray | sparse.spmatrix | pd.DataFrame | None' = None, obs: 'pd.DataFrame | Mapping[str, Iterable[Any]] | None' = None, var: 'pd.DataFrame | Mapping[str, Iterable[Any]] | None' = None, uns: 'Mapping[str, Any] | None' = None, obsm: 'np.ndarray | Mapping[str, Sequence[Any]] | None' = None, varm: 'np.ndarray | Mapping[str, Sequence[Any]] | None' = None, layers: 'Mapping[str, np.ndarray | sparse.spmatrix] | None' = None, raw: 'Mapping[str, Any] | None' = None, dtype: 'np.dtype | type | str | None' = None, shape: 'tuple[int, int] | None' = None, filename: 'PathLike | None' = None, filemode: \"Literal['r', 'r+'] | None\" = None, asview: 'bool' = False, *, obsp: 'np.ndarray | Mapping[str, Sequence[Any]] | None' = None, varp: 'np.ndarray | Mapping[str, Sequence[Any]] | None' = None, oidx: 'Index1D' = None, vidx: 'Index1D' = None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __len__(self) -> 'int'\n",
      " |  \n",
      " |  __repr__(self) -> 'str'\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setitem__(self, index: 'Index', val: 'int | float | np.ndarray | sparse.spmatrix')\n",
      " |      # TODO: Update, possibly remove\n",
      " |  \n",
      " |  __sizeof__(self, show_stratified=None, with_disk: 'bool' = False) -> 'int'\n",
      " |      Size of object in memory, in bytes.\n",
      " |  \n",
      " |  chunk_X(self, select: 'int | Sequence[int] | np.ndarray' = 1000, replace: 'bool' = True)\n",
      " |      Return a chunk of the data matrix :attr:`X` with random or specified indices.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      select\n",
      " |          Depending on the type:\n",
      " |      \n",
      " |          :class:`int`\n",
      " |              A random chunk with `select` rows will be returned.\n",
      " |          :term:`sequence` (e.g. a list, tuple or numpy array) of :class:`int`\n",
      " |              A chunk with these indices will be returned.\n",
      " |      \n",
      " |      replace\n",
      " |          If `select` is an integer then `True` means random sampling of\n",
      " |          indices with replacement, `False` without replacement.\n",
      " |  \n",
      " |  chunked_X(self, chunk_size: 'int | None' = None)\n",
      " |      Return an iterator over the rows of the data matrix :attr:`X`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      chunk_size\n",
      " |          Row size of a single chunk.\n",
      " |  \n",
      " |  concatenate(self, *adatas: 'AnnData', join: 'str' = 'inner', batch_key: 'str' = 'batch', batch_categories: 'Sequence[Any]' = None, uns_merge: 'str | None' = None, index_unique: 'str | None' = '-', fill_value=None) -> 'AnnData'\n",
      " |      Concatenate along the observations axis.\n",
      " |      \n",
      " |      The :attr:`uns`, :attr:`varm` and :attr:`obsm` attributes are ignored.\n",
      " |      \n",
      " |      Currently, this works only in `'memory'` mode.\n",
      " |      \n",
      " |      .. note::\n",
      " |      \n",
      " |          For more flexible and efficient concatenation, see: :func:`~anndata.concat`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      adatas\n",
      " |          AnnData matrices to concatenate with. Each matrix is referred to as\n",
      " |          a “batch”.\n",
      " |      join\n",
      " |          Use intersection (`'inner'`) or union (`'outer'`) of variables.\n",
      " |      batch_key\n",
      " |          Add the batch annotation to :attr:`obs` using this key.\n",
      " |      batch_categories\n",
      " |          Use these as categories for the batch annotation. By default, use increasing numbers.\n",
      " |      uns_merge\n",
      " |          Strategy to use for merging entries of uns. These strategies are applied recusivley.\n",
      " |          Currently implemented strategies include:\n",
      " |      \n",
      " |          * `None`: The default. The concatenated object will just have an empty dict for `uns`.\n",
      " |          * `\"same\"`: Only entries which have the same value in all AnnData objects are kept.\n",
      " |          * `\"unique\"`: Only entries which have one unique value in all AnnData objects are kept.\n",
      " |          * `\"first\"`: The first non-missing value is used.\n",
      " |          * `\"only\"`: A value is included if only one of the AnnData objects has a value at this\n",
      " |            path.\n",
      " |      index_unique\n",
      " |          Make the index unique by joining the existing index names with the\n",
      " |          batch category, using `index_unique='-'`, for instance. Provide\n",
      " |          `None` to keep existing indices.\n",
      " |      fill_value\n",
      " |          Scalar value to fill newly missing values in arrays with. Note: only applies to arrays\n",
      " |          and sparse matrices (not dataframes) and will only be used if `join=\"outer\"`.\n",
      " |      \n",
      " |          .. note::\n",
      " |              If not provided, the default value is `0` for sparse matrices and `np.nan`\n",
      " |              for numpy arrays. See the examples below for more information.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      :class:`~anndata.AnnData`\n",
      " |          The concatenated :class:`~anndata.AnnData`, where `adata.obs[batch_key]`\n",
      " |          stores a categorical variable labeling the batch.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |         If you use `join='outer'` this fills 0s for sparse data when\n",
      " |         variables are absent in a batch. Use this with care. Dense data is\n",
      " |         filled with `NaN`. See the examples.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Joining on intersection of variables.\n",
      " |      \n",
      " |      >>> adata1 = AnnData(\n",
      " |      ...     np.array([[1, 2, 3], [4, 5, 6]]),\n",
      " |      ...     dict(obs_names=['s1', 's2'], anno1=['c1', 'c2']),\n",
      " |      ...     dict(var_names=['a', 'b', 'c'], annoA=[0, 1, 2]),\n",
      " |      ... )\n",
      " |      >>> adata2 = AnnData(\n",
      " |      ...     np.array([[1, 2, 3], [4, 5, 6]]),\n",
      " |      ...     dict(obs_names=['s3', 's4'], anno1=['c3', 'c4']),\n",
      " |      ...     dict(var_names=['d', 'c', 'b'], annoA=[0, 1, 2]),\n",
      " |      ... )\n",
      " |      >>> adata3 = AnnData(\n",
      " |      ...     np.array([[1, 2, 3], [4, 5, 6]]),\n",
      " |      ...     dict(obs_names=['s1', 's2'], anno2=['d3', 'd4']),\n",
      " |      ...     dict(var_names=['d', 'c', 'b'], annoA=[0, 2, 3], annoB=[0, 1, 2]),\n",
      " |      ... )\n",
      " |      >>> adata = adata1.concatenate(adata2, adata3)\n",
      " |      >>> adata\n",
      " |      AnnData object with n_obs × n_vars = 6 × 2\n",
      " |          obs: 'anno1', 'anno2', 'batch'\n",
      " |          var: 'annoA-0', 'annoA-1', 'annoA-2', 'annoB-2'\n",
      " |      >>> adata.X\n",
      " |      array([[2, 3],\n",
      " |             [5, 6],\n",
      " |             [3, 2],\n",
      " |             [6, 5],\n",
      " |             [3, 2],\n",
      " |             [6, 5]])\n",
      " |      >>> adata.obs\n",
      " |           anno1 anno2 batch\n",
      " |      s1-0    c1   NaN     0\n",
      " |      s2-0    c2   NaN     0\n",
      " |      s3-1    c3   NaN     1\n",
      " |      s4-1    c4   NaN     1\n",
      " |      s1-2   NaN    d3     2\n",
      " |      s2-2   NaN    d4     2\n",
      " |      >>> adata.var.T\n",
      " |               b  c\n",
      " |      annoA-0  1  2\n",
      " |      annoA-1  2  1\n",
      " |      annoA-2  3  2\n",
      " |      annoB-2  2  1\n",
      " |      \n",
      " |      Joining on the union of variables.\n",
      " |      \n",
      " |      >>> outer = adata1.concatenate(adata2, adata3, join='outer')\n",
      " |      >>> outer\n",
      " |      AnnData object with n_obs × n_vars = 6 × 4\n",
      " |          obs: 'anno1', 'anno2', 'batch'\n",
      " |          var: 'annoA-0', 'annoA-1', 'annoA-2', 'annoB-2'\n",
      " |      >>> outer.var.T\n",
      " |                 a    b    c    d\n",
      " |      annoA-0  0.0  1.0  2.0  NaN\n",
      " |      annoA-1  NaN  2.0  1.0  0.0\n",
      " |      annoA-2  NaN  3.0  2.0  0.0\n",
      " |      annoB-2  NaN  2.0  1.0  0.0\n",
      " |      >>> outer.var_names\n",
      " |      Index(['a', 'b', 'c', 'd'], dtype='object')\n",
      " |      >>> outer.X\n",
      " |      array([[ 1.,  2.,  3., nan],\n",
      " |             [ 4.,  5.,  6., nan],\n",
      " |             [nan,  3.,  2.,  1.],\n",
      " |             [nan,  6.,  5.,  4.],\n",
      " |             [nan,  3.,  2.,  1.],\n",
      " |             [nan,  6.,  5.,  4.]])\n",
      " |      >>> outer.X.sum(axis=0)\n",
      " |      array([nan, 25., 23., nan])\n",
      " |      >>> import pandas as pd\n",
      " |      >>> Xdf = pd.DataFrame(outer.X, columns=outer.var_names)\n",
      " |      >>> Xdf\n",
      " |           a    b    c    d\n",
      " |      0  1.0  2.0  3.0  NaN\n",
      " |      1  4.0  5.0  6.0  NaN\n",
      " |      2  NaN  3.0  2.0  1.0\n",
      " |      3  NaN  6.0  5.0  4.0\n",
      " |      4  NaN  3.0  2.0  1.0\n",
      " |      5  NaN  6.0  5.0  4.0\n",
      " |      >>> Xdf.sum()\n",
      " |      a     5.0\n",
      " |      b    25.0\n",
      " |      c    23.0\n",
      " |      d    10.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      One way to deal with missing values is to use masked arrays:\n",
      " |      \n",
      " |      >>> from numpy import ma\n",
      " |      >>> outer.X = ma.masked_invalid(outer.X)\n",
      " |      >>> outer.X\n",
      " |      masked_array(\n",
      " |        data=[[1.0, 2.0, 3.0, --],\n",
      " |              [4.0, 5.0, 6.0, --],\n",
      " |              [--, 3.0, 2.0, 1.0],\n",
      " |              [--, 6.0, 5.0, 4.0],\n",
      " |              [--, 3.0, 2.0, 1.0],\n",
      " |              [--, 6.0, 5.0, 4.0]],\n",
      " |        mask=[[False, False, False,  True],\n",
      " |              [False, False, False,  True],\n",
      " |              [ True, False, False, False],\n",
      " |              [ True, False, False, False],\n",
      " |              [ True, False, False, False],\n",
      " |              [ True, False, False, False]],\n",
      " |        fill_value=1e+20)\n",
      " |      >>> outer.X.sum(axis=0).data\n",
      " |      array([ 5., 25., 23., 10.])\n",
      " |      \n",
      " |      The masked array is not saved but has to be reinstantiated after saving.\n",
      " |      \n",
      " |      >>> outer.write('./test.h5ad')\n",
      " |      >>> from anndata import read_h5ad\n",
      " |      >>> outer = read_h5ad('./test.h5ad')\n",
      " |      >>> outer.X\n",
      " |      array([[ 1.,  2.,  3., nan],\n",
      " |             [ 4.,  5.,  6., nan],\n",
      " |             [nan,  3.,  2.,  1.],\n",
      " |             [nan,  6.,  5.,  4.],\n",
      " |             [nan,  3.,  2.,  1.],\n",
      " |             [nan,  6.,  5.,  4.]])\n",
      " |      \n",
      " |      For sparse data, everything behaves similarly,\n",
      " |      except that for `join='outer'`, zeros are added.\n",
      " |      \n",
      " |      >>> from scipy.sparse import csr_matrix\n",
      " |      >>> adata1 = AnnData(\n",
      " |      ...     csr_matrix([[0, 2, 3], [0, 5, 6]], dtype=np.float32),\n",
      " |      ...     dict(obs_names=['s1', 's2'], anno1=['c1', 'c2']),\n",
      " |      ...     dict(var_names=['a', 'b', 'c']),\n",
      " |      ... )\n",
      " |      >>> adata2 = AnnData(\n",
      " |      ...     csr_matrix([[0, 2, 3], [0, 5, 6]], dtype=np.float32),\n",
      " |      ...     dict(obs_names=['s3', 's4'], anno1=['c3', 'c4']),\n",
      " |      ...     dict(var_names=['d', 'c', 'b']),\n",
      " |      ... )\n",
      " |      >>> adata3 = AnnData(\n",
      " |      ... csr_matrix([[1, 2, 0], [0, 5, 6]], dtype=np.float32),\n",
      " |      ...     dict(obs_names=['s5', 's6'], anno2=['d3', 'd4']),\n",
      " |      ...     dict(var_names=['d', 'c', 'b']),\n",
      " |      ... )\n",
      " |      >>> adata = adata1.concatenate(adata2, adata3, join='outer')\n",
      " |      >>> adata.var_names\n",
      " |      Index(['a', 'b', 'c', 'd'], dtype='object')\n",
      " |      >>> adata.X.toarray()\n",
      " |      array([[0., 2., 3., 0.],\n",
      " |             [0., 5., 6., 0.],\n",
      " |             [0., 3., 2., 0.],\n",
      " |             [0., 6., 5., 0.],\n",
      " |             [0., 0., 2., 1.],\n",
      " |             [0., 6., 5., 0.]], dtype=float32)\n",
      " |  \n",
      " |  copy(self, filename: 'PathLike | None' = None) -> 'AnnData'\n",
      " |      Full copy, optionally on disk.\n",
      " |  \n",
      " |  obs_keys(self) -> 'list[str]'\n",
      " |      List keys of observation annotation :attr:`obs`.\n",
      " |  \n",
      " |  obs_names_make_unique(self, join: 'str' = '-')\n",
      " |      Makes the index unique by appending a number string to each duplicate index element:\n",
      " |      '1', '2', etc.\n",
      " |      \n",
      " |      If a tentative name created by the algorithm already exists in the index, it tries\n",
      " |      the next integer in the sequence.\n",
      " |      \n",
      " |      The first occurrence of a non-unique value is ignored.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      join\n",
      " |           The connecting string between name and integer.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> from anndata import AnnData\n",
      " |      >>> adata = AnnData(np.ones((2, 3)), var=pd.DataFrame(index=[\"a\", \"a\", \"b\"]))\n",
      " |      >>> adata.var_names\n",
      " |      Index(['a', 'a', 'b'], dtype='object')\n",
      " |      >>> adata.var_names_make_unique()\n",
      " |      >>> adata.var_names\n",
      " |      Index(['a', 'a-1', 'b'], dtype='object')\n",
      " |  \n",
      " |  obs_vector(self, k: 'str', *, layer: 'str | None' = None) -> 'np.ndarray'\n",
      " |      Convenience function for returning a 1 dimensional ndarray of values\n",
      " |      from :attr:`X`, :attr:`layers`\\ `[k]`, or :attr:`obs`.\n",
      " |      \n",
      " |      Made for convenience, not performance.\n",
      " |      Intentionally permissive about arguments, for easy iterative use.\n",
      " |      \n",
      " |      Params\n",
      " |      ------\n",
      " |      k\n",
      " |          Key to use. Should be in :attr:`var_names` or :attr:`obs`\\ `.columns`.\n",
      " |      layer\n",
      " |          What layer values should be returned from. If `None`, :attr:`X` is used.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      A one dimensional ndarray, with values for each obs in the same order\n",
      " |      as :attr:`obs_names`.\n",
      " |  \n",
      " |  obsm_keys(self) -> 'list[str]'\n",
      " |      List keys of observation annotation :attr:`obsm`.\n",
      " |  \n",
      " |  rename_categories(self, key: 'str', categories: 'Sequence[Any]')\n",
      " |      Rename categories of annotation `key` in :attr:`obs`, :attr:`var`,\n",
      " |      and :attr:`uns`.\n",
      " |      \n",
      " |      Only supports passing a list/array-like `categories` argument.\n",
      " |      \n",
      " |      Besides calling `self.obs[key].cat.categories = categories` –\n",
      " |      similar for :attr:`var` - this also renames categories in unstructured\n",
      " |      annotation that uses the categorical annotation `key`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key\n",
      " |           Key for observations or variables annotation.\n",
      " |      categories\n",
      " |           New categories, the same number as the old categories.\n",
      " |  \n",
      " |  strings_to_categoricals(self, df: 'pd.DataFrame | None' = None)\n",
      " |      Transform string annotations to categoricals.\n",
      " |      \n",
      " |      Only affects string annotations that lead to less categories than the\n",
      " |      total number of observations.\n",
      " |      \n",
      " |      Params\n",
      " |      ------\n",
      " |      df\n",
      " |          If `df` is `None`, modifies both :attr:`obs` and :attr:`var`,\n",
      " |          otherwise modifies `df` inplace.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Turns the view of an :class:`~anndata.AnnData` into an actual\n",
      " |      :class:`~anndata.AnnData`.\n",
      " |  \n",
      " |  to_df(self, layer: 'str | None' = None) -> 'pd.DataFrame'\n",
      " |      Generate shallow :class:`~pandas.DataFrame`.\n",
      " |      \n",
      " |      The data matrix :attr:`X` is returned as\n",
      " |      :class:`~pandas.DataFrame`, where :attr:`obs_names` initializes the\n",
      " |      index, and :attr:`var_names` the columns.\n",
      " |      \n",
      " |      * No annotations are maintained in the returned object.\n",
      " |      * The data matrix is densified in case it is sparse.\n",
      " |      \n",
      " |      Params\n",
      " |      ------\n",
      " |      layer\n",
      " |          Key for `.layers`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Pandas DataFrame of specified data matrix.\n",
      " |  \n",
      " |  to_memory(self, copy=False) -> 'AnnData'\n",
      " |      Return a new AnnData object with all backed arrays loaded into memory.\n",
      " |      \n",
      " |      Params\n",
      " |      ------\n",
      " |          copy:\n",
      " |              Whether the arrays that are already in-memory should be copied.\n",
      " |      \n",
      " |      Example\n",
      " |      -------\n",
      " |      \n",
      " |      .. code:: python\n",
      " |      \n",
      " |          import anndata\n",
      " |          backed = anndata.read_h5ad(\"file.h5ad\", backed=\"r\")\n",
      " |          mem = backed[backed.obs[\"cluster\"] == \"a\", :].to_memory()\n",
      " |  \n",
      " |  transpose(self) -> 'AnnData'\n",
      " |      Transpose whole object.\n",
      " |      \n",
      " |      Data matrix is transposed, observations and variables are interchanged.\n",
      " |      Ignores `.raw`.\n",
      " |  \n",
      " |  uns_keys(self) -> 'list[str]'\n",
      " |      List keys of unstructured annotation.\n",
      " |  \n",
      " |  var_keys(self) -> 'list[str]'\n",
      " |      List keys of variable annotation :attr:`var`.\n",
      " |  \n",
      " |  var_names_make_unique(self, join: 'str' = '-')\n",
      " |      Makes the index unique by appending a number string to each duplicate index element:\n",
      " |      '1', '2', etc.\n",
      " |      \n",
      " |      If a tentative name created by the algorithm already exists in the index, it tries\n",
      " |      the next integer in the sequence.\n",
      " |      \n",
      " |      The first occurrence of a non-unique value is ignored.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      join\n",
      " |           The connecting string between name and integer.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> from anndata import AnnData\n",
      " |      >>> adata = AnnData(np.ones((2, 3)), var=pd.DataFrame(index=[\"a\", \"a\", \"b\"]))\n",
      " |      >>> adata.var_names\n",
      " |      Index(['a', 'a', 'b'], dtype='object')\n",
      " |      >>> adata.var_names_make_unique()\n",
      " |      >>> adata.var_names\n",
      " |      Index(['a', 'a-1', 'b'], dtype='object')\n",
      " |  \n",
      " |  var_vector(self, k, *, layer: 'str | None' = None) -> 'np.ndarray'\n",
      " |      Convenience function for returning a 1 dimensional ndarray of values\n",
      " |      from :attr:`X`, :attr:`layers`\\ `[k]`, or :attr:`obs`.\n",
      " |      \n",
      " |      Made for convenience, not performance. Intentionally permissive about\n",
      " |      arguments, for easy iterative use.\n",
      " |      \n",
      " |      Params\n",
      " |      ------\n",
      " |      k\n",
      " |          Key to use. Should be in :attr:`obs_names` or :attr:`var`\\ `.columns`.\n",
      " |      layer\n",
      " |          What layer values should be returned from. If `None`, :attr:`X` is used.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      A one dimensional ndarray, with values for each var in the same order\n",
      " |      as :attr:`var_names`.\n",
      " |  \n",
      " |  varm_keys(self) -> 'list[str]'\n",
      " |      List keys of variable annotation :attr:`varm`.\n",
      " |  \n",
      " |  write = write_h5ad(self, filename: 'PathLike | None' = None, compression: \"Literal['gzip', 'lzf'] | None\" = None, compression_opts: 'int | Any' = None, as_dense: 'Sequence[str]' = ())\n",
      " |  \n",
      " |  write_csvs(self, dirname: 'PathLike', skip_data: 'bool' = True, sep: 'str' = ',')\n",
      " |      Write annotation to `.csv` files.\n",
      " |      \n",
      " |      It is not possible to recover the full :class:`~anndata.AnnData` from\n",
      " |      these files. Use :meth:`write` for this.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dirname\n",
      " |          Name of directory to which to export.\n",
      " |      skip_data\n",
      " |           Skip the data matrix :attr:`X`.\n",
      " |      sep\n",
      " |           Separator for the data.\n",
      " |  \n",
      " |  write_h5ad(self, filename: 'PathLike | None' = None, compression: \"Literal['gzip', 'lzf'] | None\" = None, compression_opts: 'int | Any' = None, as_dense: 'Sequence[str]' = ())\n",
      " |      Write `.h5ad`-formatted hdf5 file.\n",
      " |      \n",
      " |      .. note::\n",
      " |         Setting compression to `'gzip'` can save disk space\n",
      " |         but will slow down writing and subsequent reading.\n",
      " |         Prior to v0.6.16, this was the default for parameter `compression`.\n",
      " |      \n",
      " |      Generally, if you have sparse data that are stored as a dense matrix,\n",
      " |      you can dramatically improve performance and reduce disk space\n",
      " |      by converting to a :class:`~scipy.sparse.csr_matrix`::\n",
      " |      \n",
      " |          from scipy.sparse import csr_matrix\n",
      " |          adata.X = csr_matrix(adata.X)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      filename\n",
      " |          Filename of data file. Defaults to backing file.\n",
      " |      compression\n",
      " |          For [`lzf`, `gzip`], see the h5py :ref:`dataset_compression`.\n",
      " |      \n",
      " |          Alternative compression filters such as `zstd` can be passed\n",
      " |          from the :doc:`hdf5plugin <hdf5plugin:usage>` library.\n",
      " |          Experimental.\n",
      " |      \n",
      " |          Usage example::\n",
      " |      \n",
      " |              import hdf5plugin\n",
      " |              adata.write_h5ad(\n",
      " |                  filename,\n",
      " |                  compression=hdf5plugin.FILTERS[\"zstd\"]\n",
      " |              )\n",
      " |      \n",
      " |          .. note::\n",
      " |              Datasets written with hdf5plugin-provided compressors\n",
      " |              cannot be opened without first loading the hdf5plugin\n",
      " |              library using `import hdf5plugin`. When using alternative\n",
      " |              compression filters such as `zstd`, consider writing to\n",
      " |              `zarr` format instead of `h5ad`, as the `zarr` library\n",
      " |              provides a more transparent compression pipeline.\n",
      " |      \n",
      " |      compression_opts\n",
      " |          For [`lzf`, `gzip`], see the h5py :ref:`dataset_compression`.\n",
      " |      \n",
      " |          Alternative compression filters such as `zstd` can be configured\n",
      " |          using helpers from the :doc:`hdf5plugin <hdf5plugin:usage>`\n",
      " |          library. Experimental.\n",
      " |      \n",
      " |          Usage example (setting `zstd` compression level to 5)::\n",
      " |      \n",
      " |              import hdf5plugin\n",
      " |              adata.write_h5ad(\n",
      " |                  filename,\n",
      " |                  compression=hdf5plugin.FILTERS[\"zstd\"],\n",
      " |                  compression_opts=hdf5plugin.Zstd(clevel=5).filter_options\n",
      " |              )\n",
      " |      \n",
      " |      as_dense\n",
      " |          Sparse arrays in AnnData object to write as dense. Currently only\n",
      " |          supports `X` and `raw/X`.\n",
      " |  \n",
      " |  write_loom(self, filename: 'PathLike', write_obsm_varm: 'bool' = False)\n",
      " |      Write `.loom`-formatted hdf5 file.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      filename\n",
      " |          The filename.\n",
      " |  \n",
      " |  write_zarr(self, store: 'MutableMapping | PathLike', chunks: 'bool | int | tuple[int, ...] | None' = None)\n",
      " |      Write a hierarchical Zarr array store.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      store\n",
      " |          The filename, a :class:`~typing.MutableMapping`, or a Zarr storage class.\n",
      " |      chunks\n",
      " |          Chunk shape.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  T\n",
      " |      Transpose whole object.\n",
      " |      \n",
      " |      Data matrix is transposed, observations and variables are interchanged.\n",
      " |      Ignores `.raw`.\n",
      " |  \n",
      " |  is_view\n",
      " |      `True` if object is view of another AnnData object, `False` otherwise.\n",
      " |  \n",
      " |  isbacked\n",
      " |      `True` if object is backed on disk, `False` otherwise.\n",
      " |  \n",
      " |  n_obs\n",
      " |      Number of observations.\n",
      " |  \n",
      " |  n_vars\n",
      " |      Number of variables/features.\n",
      " |  \n",
      " |  shape\n",
      " |      Shape of data matrix (:attr:`n_obs`, :attr:`n_vars`).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  X\n",
      " |      Data matrix of shape :attr:`n_obs` × :attr:`n_vars`.\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  filename\n",
      " |      Change to backing mode by setting the filename of a `.h5ad` file.\n",
      " |      \n",
      " |      - Setting the filename writes the stored data to disk.\n",
      " |      - Setting the filename when the filename was previously another name\n",
      " |        moves the backing file from the previous file to the new file.\n",
      " |        If you want to copy the previous file, use `copy(filename='new_filename')`.\n",
      " |  \n",
      " |  layers\n",
      " |      Dictionary-like object with values of the same dimensions as :attr:`X`.\n",
      " |      \n",
      " |      Layers in AnnData are inspired by loompy’s :ref:`loomlayers`.\n",
      " |      \n",
      " |      Return the layer named `\"unspliced\"`::\n",
      " |      \n",
      " |          adata.layers[\"unspliced\"]\n",
      " |      \n",
      " |      Create or replace the `\"spliced\"` layer::\n",
      " |      \n",
      " |          adata.layers[\"spliced\"] = ...\n",
      " |      \n",
      " |      Assign the 10th column of layer `\"spliced\"` to the variable a::\n",
      " |      \n",
      " |          a = adata.layers[\"spliced\"][:, 10]\n",
      " |      \n",
      " |      Delete the `\"spliced\"` layer::\n",
      " |      \n",
      " |          del adata.layers[\"spliced\"]\n",
      " |      \n",
      " |      Return layers’ names::\n",
      " |      \n",
      " |          adata.layers.keys()\n",
      " |  \n",
      " |  obs\n",
      " |      One-dimensional annotation of observations (`pd.DataFrame`).\n",
      " |  \n",
      " |  obs_names\n",
      " |      Names of observations (alias for `.obs.index`).\n",
      " |  \n",
      " |  obsm\n",
      " |      Multi-dimensional annotation of observations\n",
      " |      (mutable structured :class:`~numpy.ndarray`).\n",
      " |      \n",
      " |      Stores for each key a two or higher-dimensional :class:`~numpy.ndarray`\n",
      " |      of length `n_obs`.\n",
      " |      Is sliced with `data` and `obs` but behaves otherwise like a :term:`mapping`.\n",
      " |  \n",
      " |  obsp\n",
      " |      Pairwise annotation of observations,\n",
      " |      a mutable mapping with array-like values.\n",
      " |      \n",
      " |      Stores for each key a two or higher-dimensional :class:`~numpy.ndarray`\n",
      " |      whose first two dimensions are of length `n_obs`.\n",
      " |      Is sliced with `data` and `obs` but behaves otherwise like a :term:`mapping`.\n",
      " |  \n",
      " |  raw\n",
      " |      Store raw version of :attr:`X` and :attr:`var` as `.raw.X` and `.raw.var`.\n",
      " |      \n",
      " |      The :attr:`raw` attribute is initialized with the current content\n",
      " |      of an object by setting::\n",
      " |      \n",
      " |          adata.raw = adata\n",
      " |      \n",
      " |      Its content can be deleted::\n",
      " |      \n",
      " |          adata.raw = None\n",
      " |          # or\n",
      " |          del adata.raw\n",
      " |      \n",
      " |      Upon slicing an AnnData object along the obs (row) axis, :attr:`raw`\n",
      " |      is also sliced. Slicing an AnnData object along the vars (columns) axis\n",
      " |      leaves :attr:`raw` unaffected. Note that you can call::\n",
      " |      \n",
      " |           adata.raw[:, 'orig_variable_name'].X\n",
      " |      \n",
      " |      to retrieve the data associated with a variable that might have been\n",
      " |      filtered out or \"compressed away\" in :attr:`X`.\n",
      " |  \n",
      " |  uns\n",
      " |      Unstructured annotation (ordered dictionary).\n",
      " |  \n",
      " |  var\n",
      " |      One-dimensional annotation of variables/ features (`pd.DataFrame`).\n",
      " |  \n",
      " |  var_names\n",
      " |      Names of variables (alias for `.var.index`).\n",
      " |  \n",
      " |  varm\n",
      " |      Multi-dimensional annotation of variables/features\n",
      " |      (mutable structured :class:`~numpy.ndarray`).\n",
      " |      \n",
      " |      Stores for each key a two or higher-dimensional :class:`~numpy.ndarray`\n",
      " |      of length `n_vars`.\n",
      " |      Is sliced with `data` and `var` but behaves otherwise like a :term:`mapping`.\n",
      " |  \n",
      " |  varp\n",
      " |      Pairwise annotation of variables/features,\n",
      " |      a mutable mapping with array-like values.\n",
      " |      \n",
      " |      Stores for each key a two or higher-dimensional :class:`~numpy.ndarray`\n",
      " |      whose first two dimensions are of length `n_var`.\n",
      " |      Is sliced with `data` and `var` but behaves otherwise like a :term:`mapping`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __hash__ = None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fwal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
