{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (10000, 6)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate 10,000 entries and 2 random features\n",
    "independent_features = np.random.rand(10000, 2)\n",
    "\n",
    "# Create features based on polynomial combinations\n",
    "feature_cos = np.cos(independent_features[:, 0] + independent_features[:, 1])\n",
    "feature_tan = np.tan(independent_features[:, 0] * independent_features[:, 1])\n",
    "feature_sin = np.sin(independent_features[:, 0]**2 + independent_features[:, 1]**2)\n",
    "\n",
    "# Combine all features into a single array\n",
    "dataset = np.column_stack((independent_features, feature_cos, feature_tan, feature_sin))\n",
    "\n",
    "# Add a final feature as a simple polynomial combination\n",
    "final_feature_continuous = (\n",
    "    2 * dataset[:, 0] +\n",
    "    3 * dataset[:, 1] +\n",
    "    0.5 * dataset[:, 2] +\n",
    "    1.5 * dataset[:, 3] +\n",
    "    0.8 * dataset[:, 4] +\n",
    "    np.random.normal(scale=0.1, size=(10000,))\n",
    ")\n",
    "\n",
    "# Convert continuous values to binary (0 or 1) using a threshold\n",
    "threshold = np.median(final_feature_continuous)\n",
    "final_feature_binary = (final_feature_continuous > threshold).astype(int)\n",
    "\n",
    "# Add the final feature to the dataset\n",
    "dataset = np.column_stack((dataset, final_feature_binary))\n",
    "\n",
    "# Print the shape of the generated dataset\n",
    "print(\"Shape of the dataset:\", dataset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.37454012 0.95071431 0.24308201 0.37193478 0.86449157 1.        ]\n",
      " [0.73199394 0.59865848 0.2378424  0.46860099 0.77971287 1.        ]\n",
      " [0.15601864 0.15599452 0.95171751 0.02434286 0.04865689 0.        ]\n",
      " [0.05808361 0.86617615 0.6024256  0.05035313 0.68429381 0.        ]\n",
      " [0.60111501 0.70807258 0.25863489 0.4533461  0.7596053  1.        ]\n",
      " [0.02058449 0.96990985 0.54827651 0.01996776 0.80823514 1.        ]\n",
      " [0.83244264 0.21233911 0.50209068 0.17862434 0.67284562 0.        ]\n",
      " [0.18182497 0.18340451 0.93404182 0.03335989 0.06664809 0.        ]\n",
      " [0.30424224 0.52475643 0.67561433 0.16102352 0.35968722 0.        ]\n",
      " [0.43194502 0.29122914 0.74970895 0.12646275 0.2680717  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset[:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('/home/er647/projects/feature-wise-active-learning/data/SyntheticData/simple_synthetic_dataset.csv', dataset, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Dataset:\n",
      "[[0.37454012 0.95071431 0.24308201 0.37193478 0.86449157 1.        ]\n",
      " [0.73199394 0.59865848 0.2378424  0.46860099 0.77971287 1.        ]\n",
      " [0.15601864 0.15599452 0.95171751 0.02434286 0.04865689 0.        ]\n",
      " [0.05808361 0.86617615 0.6024256  0.05035313 0.68429381 0.        ]\n",
      " [0.60111501 0.70807258 0.25863489 0.4533461  0.7596053  1.        ]\n",
      " [0.02058449 0.96990985 0.54827651 0.01996776 0.80823514 1.        ]\n",
      " [0.83244264 0.21233911 0.50209068 0.17862434 0.67284562 0.        ]\n",
      " [0.18182497 0.18340451 0.93404182 0.03335989 0.06664809 0.        ]\n",
      " [0.30424224 0.52475643 0.67561433 0.16102352 0.35968722 0.        ]\n",
      " [0.43194502 0.29122914 0.74970895 0.12646275 0.2680717  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Specify the path to the CSV file\n",
    "csv_file_path = '/home/er647/projects/feature-wise-active-learning/data/SyntheticData/simple_synthetic_dataset.csv'  # Replace with the actual path to your CSV file\n",
    "\n",
    "# Load the dataset from the CSV file\n",
    "loaded_dataset = np.loadtxt(csv_file_path, delimiter=\",\")\n",
    "\n",
    "# Print the loaded dataset\n",
    "print(\"Loaded Dataset:\")\n",
    "print(loaded_dataset[:10,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (10000, 6)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate 10,000 entries and 2 random features\n",
    "independent_features = np.random.rand(10000, 2)\n",
    "\n",
    "# Create features based on polynomial combinations\n",
    "feature_1 = 1*independent_features[:, 0] + 2*independent_features[:, 1]\n",
    "feature_2 = 3*independent_features[:, 0] * 4*independent_features[:, 1]\n",
    "feature_3 = 5*independent_features[:, 0] + 6*independent_features[:, 1]\n",
    "\n",
    "# Combine all features into a single array\n",
    "dataset = np.column_stack((independent_features, feature_1, feature_2, feature_3))\n",
    "\n",
    "# Add a final feature as a simple polynomial combination\n",
    "final_feature_continuous = (\n",
    "    2 * dataset[:, 0] +\n",
    "    3 * dataset[:, 1] +\n",
    "    0.5 * dataset[:, 2] +\n",
    "    1.5 * dataset[:, 3] +\n",
    "    0.8 * dataset[:, 4] +\n",
    "    np.random.normal(scale=0.1, size=(10000,))\n",
    ")\n",
    "\n",
    "# Convert continuous values to binary (0 or 1) using a threshold\n",
    "threshold = np.median(final_feature_continuous)\n",
    "final_feature_binary = (final_feature_continuous > threshold).astype(int)\n",
    "\n",
    "# Add the final feature to the dataset\n",
    "dataset = np.column_stack((dataset, final_feature_binary))\n",
    "\n",
    "# Print the shape of the generated dataset\n",
    "print(\"Shape of the dataset:\", dataset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('/home/er647/projects/feature-wise-active-learning/data/SyntheticData/very_simple_synthetic_dataset.csv', dataset, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Dataset:\n",
      "[[0.37454012 0.95071431 2.27596873 4.27296779 7.57698643 1.        ]\n",
      " [0.73199394 0.59865848 1.92931091 5.2585726  7.25192061 1.        ]\n",
      " [0.15601864 0.15599452 0.46800768 0.29205664 1.71606032 0.        ]\n",
      " [0.05808361 0.86617615 1.7904359  0.60372767 5.48747494 0.        ]\n",
      " [0.60111501 0.70807258 2.01726017 5.10759667 7.25401053 1.        ]\n",
      " [0.02058449 0.96990985 1.9604042  0.23958125 5.92238158 0.        ]\n",
      " [0.83244264 0.21233911 1.25712086 2.12112156 5.43624787 0.        ]\n",
      " [0.18182497 0.18340451 0.54863399 0.40017023 2.0095519  0.        ]\n",
      " [0.30424224 0.52475643 1.35375511 1.91583689 4.6697498  0.        ]\n",
      " [0.43194502 0.29122914 1.0144033  1.50953972 3.90709993 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Specify the path to the CSV file\n",
    "csv_file_path = '/home/er647/projects/feature-wise-active-learning/data/SyntheticData/very_simple_synthetic_dataset.csv'  # Replace with the actual path to your CSV file\n",
    "\n",
    "# Load the dataset from the CSV file\n",
    "loaded_dataset = np.loadtxt(csv_file_path, delimiter=\",\")\n",
    "\n",
    "# Print the loaded dataset\n",
    "print(\"Loaded Dataset:\")\n",
    "print(loaded_dataset[:10,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FWAL_kernel",
   "language": "python",
   "name": "fwal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
